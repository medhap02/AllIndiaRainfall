{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import cartopy as cp\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import cftime\n",
    "import dateutil\n",
    "import dask\n",
    "#Use the 2 lines below if the notebook has a dark theme (to make labelling visible):\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='chesterish', context='notebook', ticks=True, grid=False)\n",
    "import matplotlib.pyplot as plt\n",
    "#The following code resets the default plot size so you don't have to fiddle with figsize every time\"\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 16\n",
    "fig_size[1] = 8\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HDF5_USE_FILE_LOCKING=FALSE\n"
     ]
    }
   ],
   "source": [
    "#Need the following line to avoid hdf5 issues that prevent opening thee file\n",
    "# https://stackoverflow.com/questions/49317927/errno-101-netcdf-hdf-error-when-opening-netcdf-file\n",
    "%env HDF5_USE_FILE_LOCKING=FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load AIRI data \n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import num2date, date2num\n",
    "dataset_file = \"pALLIN.nc\"\n",
    "airi_dat = xr.open_dataset(dataset_file, decode_times=False)\n",
    "units, reference_date = airi_dat.time.attrs['units'].split('since')\n",
    "airi_dat['time'] = pd.date_range(start=reference_date, periods=airi_dat.sizes['time'], freq='MS')\n",
    "#This file's calendar isn't recognized when using xr.open_dataset. The above workaround is from: \n",
    "#https://stackoverflow.com/questions/55648630/how-to-decode-the-time-variable-while-using-xarray-to-load-a-netcdf-file\n",
    "# \"M\" means \"month end frequency\" (see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 1752)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1871-02-01 1871-03-01 ... 2017-01-01\n",
       "Data variables:\n",
       "    precip   (time) float32 ...\n",
       "Attributes:\n",
       "    title:        \n",
       "    description:  All-India Rainfall\n",
       "    scripturl01:  https://climexp.knmi.nl/getindices.cgi?STATION=All-India_Ra...\n",
       "    comment:      \n",
       "    institution:  KNMI Climate Explorer\n",
       "    scripturl02:  https://climexp.knmi.nl/dat2nc.cgi?id=$id&station=All-India...\n",
       "    history:       2020-04-02  2:43:20 bin/dat2nc data/pALLIN.dat p All-India...\n",
       "    Conventions:  CF-1.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airi_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip = airi_dat['precip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load SST data\n",
    "dataset_url = \"https://psl.noaa.gov/thredds/dodsC/Datasets/noaa.ersst.v5/sst.mnmean.nc\"\n",
    "sst_dat = xr.open_dataset(dataset_url)\n",
    "sst = sst_dat['sst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/medhap02/.conda/envs/xarrayenv2/lib/python3.7/site-packages/xarray/core/nanops.py:160: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'sst' (time: 1752, lat: 89, lon: 180)>\n",
       "array([[[1.788139e-06, 1.788139e-06, ..., 1.788139e-06, 1.788139e-06],\n",
       "        [1.788139e-06, 1.788139e-06, ..., 1.788139e-06, 1.788139e-06],\n",
       "        ...,\n",
       "        [         nan,          nan, ...,          nan,          nan],\n",
       "        [         nan,          nan, ...,          nan,          nan]],\n",
       "\n",
       "       [[1.788139e-06, 1.788139e-06, ..., 1.788139e-06, 1.788139e-06],\n",
       "        [1.788139e-06, 1.788139e-06, ..., 1.788139e-06, 1.788139e-06],\n",
       "        ...,\n",
       "        [         nan,          nan, ...,          nan,          nan],\n",
       "        [         nan,          nan, ...,          nan,          nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[3.152323e-02, 2.609873e-02, ..., 2.140296e-02, 3.102016e-02],\n",
       "        [2.697122e-02, 1.542413e-02, ..., 1.046002e-02, 2.427316e-02],\n",
       "        ...,\n",
       "        [         nan,          nan, ...,          nan,          nan],\n",
       "        [         nan,          nan, ...,          nan,          nan]],\n",
       "\n",
       "       [[1.788139e-06, 1.788139e-06, ..., 1.788139e-06, 1.788139e-06],\n",
       "        [1.788139e-06, 1.788139e-06, ..., 1.788139e-06, 1.788139e-06],\n",
       "        ...,\n",
       "        [         nan,          nan, ...,          nan,          nan],\n",
       "        [         nan,          nan, ...,          nan,          nan]]],\n",
       "      dtype=float32)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 88.0 86.0 84.0 82.0 80.0 ... -82.0 -84.0 -86.0 -88.0\n",
       "  * lon      (lon) float32 0.0 2.0 4.0 6.0 8.0 ... 350.0 352.0 354.0 356.0 358.0\n",
       "  * time     (time) datetime64[ns] 1871-02-01 1871-03-01 ... 2017-01-01\n",
       "    month    (time) int64 2 3 4 5 6 7 8 9 10 11 12 ... 3 4 5 6 7 8 9 10 11 12 1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Slice SST data to the same duration as precip and calculate monthly anomalies\n",
    "sst_subset = sst.sel(time=slice('1871-01-30','2017-01-01'))\n",
    "sst_clim = sst_subset.groupby('time.month').mean('time')\n",
    "sst_anomfull = sst_subset.groupby(\"time.month\")-sst_clim\n",
    "sst_anomfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 89, lon: 180, time: 1056)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-01-01 1900-02-01 ... 2015-12-01\n",
      "  * lat      (lat) float32 88.0 86.0 84.0 82.0 80.0 ... -82.0 -84.0 -86.0 -88.0\n",
      "  * lon      (lon) float32 0.0 2.0 4.0 6.0 8.0 ... 350.0 352.0 354.0 356.0 358.0\n",
      "    month    (time) float64 1.0 2.0 3.0 4.0 5.0 6.0 ... 8.0 9.0 10.0 11.0 12.0\n",
      "Data variables:\n",
      "    sst      (time, lat, lon) float32 1.7881393e-06 1.7881393e-06 ... nan nan\n"
     ]
    }
   ],
   "source": [
    "sst_subset1 = sst_anomfull.sel(time=slice('1900-01-01','1901-12-31'))\n",
    "sst_subset2 = sst_anomfull.sel(time=slice('1903-01-01','1906-12-31'))\n",
    "sst_subset3 = sst_anomfull.sel(time=slice('1908-01-01','1911-12-31'))\n",
    "sst_subset4 = sst_anomfull.sel(time=slice('1913-01-01','1913-12-31'))\n",
    "sst_subset5 = sst_anomfull.sel(time=slice('1915-01-01','1918-12-31'))\n",
    "sst_subset6 = sst_anomfull.sel(time=slice('1920-01-01','1921-12-31'))\n",
    "sst_subset7 = sst_anomfull.sel(time=slice('1923-01-01','1927-12-31'))\n",
    "sst_subset8 = sst_anomfull.sel(time=slice('1929-01-01','1931-12-31'))\n",
    "sst_subset9 = sst_anomfull.sel(time=slice('1934-01-01','1939-12-31'))\n",
    "sst_subset10 = sst_anomfull.sel(time=slice('1941-01-01','1948-12-31'))\n",
    "sst_subset11 = sst_anomfull.sel(time=slice('1951-01-01','1955-12-31'))\n",
    "sst_subset12 = sst_anomfull.sel(time=slice('1957-01-01','1958-12-31'))\n",
    "sst_subset13 = sst_anomfull.sel(time=slice('1960-01-01','1962-12-31'))\n",
    "sst_subset13 = sst_anomfull.sel(time=slice('1964-01-01','1965-12-31'))\n",
    "sst_subset14 = sst_anomfull.sel(time=slice('1967-01-01','1971-12-31'))\n",
    "sst_subset15 = sst_anomfull.sel(time=slice('1973-01-01','1976-12-31'))\n",
    "sst_subset16 = sst_anomfull.sel(time=slice('1978-01-01','1979-12-31'))\n",
    "sst_subset17 = sst_anomfull.sel(time=slice('1981-01-01','1982-12-31'))\n",
    "sst_subset18 = sst_anomfull.sel(time=slice('1984-01-01','1991-12-31'))\n",
    "sst_subset19 = sst_anomfull.sel(time=slice('1993-01-01','1998-12-31'))\n",
    "sst_subset20 = sst_anomfull.sel(time=slice('2000-01-01','2002-12-31'))\n",
    "sst_subset21 = sst_anomfull.sel(time=slice('2004-01-01','2006-12-31'))\n",
    "sst_subset22 = sst_anomfull.sel(time=slice('2008-01-01','2010-12-31'))\n",
    "sst_subset23 = sst_anomfull.sel(time=slice('2012-01-01','2015-12-31'))\n",
    "\n",
    "sst_anomtemp = xr.merge([sst_subset1, sst_subset2, sst_subset3, sst_subset4, sst_subset5, \n",
    "                   sst_subset6, sst_subset7, sst_subset8, sst_subset9, sst_subset10, \n",
    "                   sst_subset11, sst_subset12, sst_subset13, sst_subset14, sst_subset15, \n",
    "                   sst_subset16, sst_subset17, sst_subset18, sst_subset19, sst_subset20, \n",
    "                   sst_subset21, sst_subset22, sst_subset23])\n",
    "#sst_anom = xr.Dataset.to_array(sst_anomtemp).drop('variable')\n",
    "print(sst_anomtemp)\n",
    "sst_anom = sst_anomtemp['sst']\n",
    "#1902, 1907, 1912, 1914, 1919, 1922, 1928, 1932, 1933, 1940\n",
    "#1949, 1950, 1956, 1959, 1963, 1966, 1972, 1977, 1980, 1983\n",
    "#1992, 1999, 2003, 2007, 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load SLP data\n",
    "dataset_url = \"/global/scratch/medhap02/prmsl.mon.mean.nc\"\n",
    "slp_dat = xr.open_dataset(dataset_url)\n",
    "slp = slp_dat['prmsl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'prmsl' (time: 1740, lat: 181, lon: 360)>\n",
       "array([[[  114.765625,   114.765625, ...,   114.765625,   114.765625],\n",
       "        [   94.78125 ,    94.46875 , ...,    95.359375,    95.03125 ],\n",
       "        ...,\n",
       "        [  293.65625 ,   293.95312 , ...,   293.20312 ,   293.4297  ],\n",
       "        [  288.66406 ,   288.66406 , ...,   288.66406 ,   288.66406 ]],\n",
       "\n",
       "       [[   75.84375 ,    75.84375 , ...,    75.84375 ,    75.84375 ],\n",
       "        [   67.66406 ,    68.02344 , ...,    66.85156 ,    67.24219 ],\n",
       "        ...,\n",
       "        [  587.2969  ,   587.52344 , ...,   586.9219  ,   587.0781  ],\n",
       "        [  581.14844 ,   581.14844 , ...,   581.14844 ,   581.14844 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ -876.5703  ,  -876.5703  , ...,  -876.5703  ,  -876.5703  ],\n",
       "        [ -937.10156 ,  -936.8594  , ...,  -937.625   ,  -937.3906  ],\n",
       "        ...,\n",
       "        [-1008.4375  , -1008.8906  , ..., -1007.5625  , -1007.9922  ],\n",
       "        [-1047.0938  , -1047.0938  , ..., -1047.0938  , -1047.0938  ]],\n",
       "\n",
       "       [[ -525.5     ,  -525.5     , ...,  -525.5     ,  -525.5     ],\n",
       "        [ -584.5703  ,  -584.8828  , ...,  -583.8906  ,  -584.2578  ],\n",
       "        ...,\n",
       "        [ -427.9922  ,  -428.3203  , ...,  -427.28125 ,  -427.6172  ],\n",
       "        [ -411.48438 ,  -411.48438 , ...,  -411.48438 ,  -411.48438 ]]],\n",
       "      dtype=float32)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 -90.0 -89.0 -88.0 -87.0 -86.0 ... 87.0 88.0 89.0 90.0\n",
       "  * lon      (lon) float32 0.0 1.0 2.0 3.0 4.0 ... 355.0 356.0 357.0 358.0 359.0\n",
       "  * time     (time) datetime64[ns] 1871-01-01 1871-02-01 ... 2015-12-01\n",
       "    month    (time) int64 1 2 3 4 5 6 7 8 9 10 11 ... 2 3 4 5 6 7 8 9 10 11 12"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Slice SLP data to the same duration as precip and calculate monthly anomalies\n",
    "slp_subset = slp.sel(time=slice('1871-01-01','2015-12-31'))\n",
    "slp_clim = slp_subset.groupby('time.month').mean('time')\n",
    "slp_anomfull = slp_subset.groupby(\"time.month\")-slp_clim\n",
    "slp_anomfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 181, lon: 360, time: 1056)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-01-01 1900-02-01 ... 2015-12-01\n",
      "  * lat      (lat) float32 -90.0 -89.0 -88.0 -87.0 -86.0 ... 87.0 88.0 89.0 90.0\n",
      "  * lon      (lon) float32 0.0 1.0 2.0 3.0 4.0 ... 355.0 356.0 357.0 358.0 359.0\n",
      "    month    (time) float64 1.0 2.0 3.0 4.0 5.0 6.0 ... 8.0 9.0 10.0 11.0 12.0\n",
      "Data variables:\n",
      "    prmsl    (time, lat, lon) float32 24.570312 24.570312 ... -411.48438\n"
     ]
    }
   ],
   "source": [
    "slp_subset1 = slp_anomfull.sel(time=slice('1900-01-01','1901-12-31'))\n",
    "slp_subset2 = slp_anomfull.sel(time=slice('1903-01-01','1906-12-31'))\n",
    "slp_subset3 = slp_anomfull.sel(time=slice('1908-01-01','1911-12-31'))\n",
    "slp_subset4 = slp_anomfull.sel(time=slice('1913-01-01','1913-12-31'))\n",
    "slp_subset5 = slp_anomfull.sel(time=slice('1915-01-01','1918-12-31'))\n",
    "slp_subset6 = slp_anomfull.sel(time=slice('1920-01-01','1921-12-31'))\n",
    "slp_subset7 = slp_anomfull.sel(time=slice('1923-01-01','1927-12-31'))\n",
    "slp_subset8 = slp_anomfull.sel(time=slice('1929-01-01','1931-12-31'))\n",
    "slp_subset9 = slp_anomfull.sel(time=slice('1934-01-01','1939-12-31'))\n",
    "slp_subset10 = slp_anomfull.sel(time=slice('1941-01-01','1948-12-31'))\n",
    "slp_subset11 = slp_anomfull.sel(time=slice('1951-01-01','1955-12-31'))\n",
    "slp_subset12 = slp_anomfull.sel(time=slice('1957-01-01','1958-12-31'))\n",
    "slp_subset13 = slp_anomfull.sel(time=slice('1960-01-01','1962-12-31'))\n",
    "slp_subset13 = slp_anomfull.sel(time=slice('1964-01-01','1965-12-31'))\n",
    "slp_subset14 = slp_anomfull.sel(time=slice('1967-01-01','1971-12-31'))\n",
    "slp_subset15 = slp_anomfull.sel(time=slice('1973-01-01','1976-12-31'))\n",
    "slp_subset16 = slp_anomfull.sel(time=slice('1978-01-01','1979-12-31'))\n",
    "slp_subset17 = slp_anomfull.sel(time=slice('1981-01-01','1982-12-31'))\n",
    "slp_subset18 = slp_anomfull.sel(time=slice('1984-01-01','1991-12-31'))\n",
    "slp_subset19 = slp_anomfull.sel(time=slice('1993-01-01','1998-12-31'))\n",
    "slp_subset20 = slp_anomfull.sel(time=slice('2000-01-01','2002-12-31'))\n",
    "slp_subset21 = slp_anomfull.sel(time=slice('2004-01-01','2006-12-31'))\n",
    "slp_subset22 = slp_anomfull.sel(time=slice('2008-01-01','2010-12-31'))\n",
    "slp_subset23 = slp_anomfull.sel(time=slice('2012-01-01','2015-12-31'))\n",
    "\n",
    "slp_anomtemp = xr.merge([slp_subset1, slp_subset2, slp_subset3, slp_subset4, slp_subset5, \n",
    "                   slp_subset6, slp_subset7, slp_subset8, slp_subset9, slp_subset10, \n",
    "                   slp_subset11, slp_subset12, slp_subset13, slp_subset14, slp_subset15, \n",
    "                   slp_subset16, slp_subset17, slp_subset18, slp_subset19, slp_subset20, \n",
    "                   slp_subset21, slp_subset22, slp_subset23])\n",
    "#slp_anom = xr.Dataset.to_array(slp_anomtemp).drop('variable')\n",
    "print(slp_anomtemp)\n",
    "slp_anom = slp_anomtemp['prmsl']\n",
    "#1902, 1907, 1912, 1914, 1919, 1922, 1928, 1932, 1933, 1940\n",
    "#1949, 1950, 1956, 1959, 1963, 1966, 1972, 1977, 1980, 1983\n",
    "#1992, 1999, 2003, 2007, 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get precip anomalies\n",
    "precip_clim = precip.groupby(\"time.month\").mean(\"time\")\n",
    "precip_anomfull = precip.groupby(\"time.month\") - precip_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'precip' (time: 1056)>\n",
      "array([ -9.166439,   4.535616,  -5.745206, ..., -44.439735, -40.930824,\n",
      "        13.444523], dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-01-01 1900-02-01 ... 2015-12-01\n",
      "    month    (time) float64 1.0 2.0 3.0 4.0 5.0 6.0 ... 8.0 9.0 10.0 11.0 12.0\n"
     ]
    }
   ],
   "source": [
    "precip_subset1 = precip_anomfull.sel(time=slice('1900-01-01','1901-12-31'))\n",
    "precip_subset2 = precip_anomfull.sel(time=slice('1903-01-01','1906-12-31'))\n",
    "precip_subset3 = precip_anomfull.sel(time=slice('1908-01-01','1911-12-31'))\n",
    "precip_subset4 = precip_anomfull.sel(time=slice('1913-01-01','1913-12-31'))\n",
    "precip_subset5 = precip_anomfull.sel(time=slice('1915-01-01','1918-12-31'))\n",
    "precip_subset6 = precip_anomfull.sel(time=slice('1920-01-01','1921-12-31'))\n",
    "precip_subset7 = precip_anomfull.sel(time=slice('1923-01-01','1927-12-31'))\n",
    "precip_subset8 = precip_anomfull.sel(time=slice('1929-01-01','1931-12-31'))\n",
    "precip_subset9 = precip_anomfull.sel(time=slice('1934-01-01','1939-12-31'))\n",
    "precip_subset10 = precip_anomfull.sel(time=slice('1941-01-01','1948-12-31'))\n",
    "precip_subset11 = precip_anomfull.sel(time=slice('1951-01-01','1955-12-31'))\n",
    "precip_subset12 = precip_anomfull.sel(time=slice('1957-01-01','1958-12-31'))\n",
    "precip_subset13 = precip_anomfull.sel(time=slice('1960-01-01','1962-12-31'))\n",
    "precip_subset13 = precip_anomfull.sel(time=slice('1964-01-01','1965-12-31'))\n",
    "precip_subset14 = precip_anomfull.sel(time=slice('1967-01-01','1971-12-31'))\n",
    "precip_subset15 = precip_anomfull.sel(time=slice('1973-01-01','1976-12-31'))\n",
    "precip_subset16 = precip_anomfull.sel(time=slice('1978-01-01','1979-12-31'))\n",
    "precip_subset17 = precip_anomfull.sel(time=slice('1981-01-01','1982-12-31'))\n",
    "precip_subset18 = precip_anomfull.sel(time=slice('1984-01-01','1991-12-31'))\n",
    "precip_subset19 = precip_anomfull.sel(time=slice('1993-01-01','1998-12-31'))\n",
    "precip_subset20 = precip_anomfull.sel(time=slice('2000-01-01','2002-12-31'))\n",
    "precip_subset21 = precip_anomfull.sel(time=slice('2004-01-01','2006-12-31'))\n",
    "precip_subset22 = precip_anomfull.sel(time=slice('2008-01-01','2010-12-31'))\n",
    "precip_subset23 = precip_anomfull.sel(time=slice('2012-01-01','2015-12-31'))\n",
    "\n",
    "precip_anom = xr.merge([precip_subset1, precip_subset2, precip_subset3, precip_subset4, precip_subset5, \n",
    "                   precip_subset6, precip_subset7, precip_subset8, precip_subset9, precip_subset10, \n",
    "                   precip_subset11, precip_subset12, precip_subset13, precip_subset14, precip_subset15, \n",
    "                   precip_subset16, precip_subset17, precip_subset18, precip_subset19, precip_subset20, \n",
    "                   precip_subset21, precip_subset22, precip_subset23])\n",
    "precip_anomtemp = xr.Dataset.to_array(precip_anom)\n",
    "precip_anom = precip_anom['precip']\n",
    "print(precip_anom)\n",
    "#1902, 1907, 1912, 1914, 1919, 1922, 1928, 1932, 1933, 1940\n",
    "#1949, 1950, 1956, 1959, 1963, 1966, 1972, 1977, 1980, 1983\n",
    "#1992, 1999, 2003, 2007, 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "junes = np.arange(5,1056,12)\n",
    "julys = np.arange(6,1056,12) #1752 instead of 1068\n",
    "augusts = np.arange(7,1056, 12)\n",
    "septembers = np.arange(8,1056,12)\n",
    "precipa_june = precip_anom[junes]\n",
    "precipa_july = precip_anom[julys]\n",
    "precipa_august = precip_anom[augusts]\n",
    "precipa_september = precip_anom[septembers]\n",
    "\n",
    "precipa_july.time.data = precipa_june.time.data\n",
    "precipa_august.time.data = precipa_june.time.data\n",
    "precipa_september.time.data = precipa_june.time.data\n",
    "\n",
    "precipa_jjas = (precipa_june + precipa_july + precipa_august + precipa_september)\n",
    "precipa_jjas.time.data = EPT.time.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x, y, dims=None):\n",
    "    return xr.dot(x - x.mean(dims), y - y.mean(dims), dims=dims) / x.count(dims)\n",
    "\n",
    "def correlation(x, y, dims=None):\n",
    "    return covariance(x, y, dims) / (x.std(dims) * y.std(dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (time: 88)>\n",
      "array([-1.001022e+00,  4.092521e-01, -8.242461e-02, -3.950637e-01,\n",
      "       -1.991887e+00, -5.299378e-01,  1.560524e+00,  9.171774e-01,\n",
      "        1.861798e+00,  7.184782e-01,  5.132719e-01, -1.393943e+00,\n",
      "        6.510655e-01, -8.583212e-01, -1.542083e+00, -5.391475e-01,\n",
      "        7.739933e-01, -1.586646e-01,  2.022947e+00, -1.050585e+00,\n",
      "       -9.153548e-01, -3.219801e-01, -3.372386e-01, -2.678311e-01,\n",
      "       -1.133814e+00, -3.801206e-01,  2.781658e-01, -1.719525e-01,\n",
      "       -6.795717e-01,  1.400972e+00, -8.641061e-01, -2.277115e+00,\n",
      "        3.372310e-01,  6.574911e-01,  1.270842e-02,  3.108336e-01,\n",
      "        1.808633e+00,  6.328033e-01, -1.012164e+00, -1.072956e-01,\n",
      "       -6.848660e-01, -1.839094e+00,  1.232946e+00,  4.221162e-01,\n",
      "       -1.384519e+00, -1.189353e+00,  1.413989e+00, -1.641494e+00,\n",
      "        4.898613e-01,  1.438546e+00, -1.031586e+00,  9.106532e-01,\n",
      "        8.513597e-01,  5.350164e-01,  3.352629e-01,  4.771452e-01,\n",
      "       -1.099682e-02,  7.402413e-01, -2.898074e-02,  5.349081e-01,\n",
      "       -1.517074e-02,  4.618538e-02,  1.032259e+00,  1.107482e+00,\n",
      "       -1.993838e+00,  8.391818e-01,  8.212456e-01,  3.590105e-01,\n",
      "       -2.347805e-03, -2.042291e+00,  6.236740e-01,  1.143536e+00,\n",
      "        1.095853e+00, -8.193700e-01, -2.848685e+00, -7.865539e-02,\n",
      "        3.195175e-01,  1.681927e-01,  9.318367e-01,  6.360353e-01,\n",
      "        7.019784e-01, -4.267737e-01,  3.707018e-01,  6.974803e-02,\n",
      "       -6.191818e-01,  7.154179e-01, -1.123229e-01, -4.500980e-01],\n",
      "      dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n",
      "    month    (time) float64 3.0 3.0 3.0 3.0 3.0 3.0 ... 3.0 3.0 3.0 3.0 3.0 3.0\n"
     ]
    }
   ],
   "source": [
    "#EPT original\n",
    "\n",
    "#DSST1\n",
    "latrange1 = sst_anom.sel(lat = slice(5, -20)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "marchdata1 = sst_anom.sel(lat = slice(5, -20), lon = slice(150, 170), time = (sst_anom['time.month']==3))\n",
    "marchSST1 = marchdata1.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean1 = (marchSST1*weights1).mean({'lon', 'lat'})/weights1.mean() \n",
    "\n",
    "aprildata1 = sst_anom.sel(lat = slice(5, -20), lon = slice(150, 170), time = (sst_anom['time.month']==4))\n",
    "aprilSST1 = aprildata1.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean1 = (aprilSST1*weights1).mean({'lon', 'lat'})/weights1.mean() \n",
    "\n",
    "maydata1 = sst_anom.sel(lat = slice(5, -20), lon = slice(150, 170), time = (sst_anom['time.month']==5))\n",
    "maySST1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = (maySST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "marchmean1.time.data = maymean1.time.data\n",
    "aprilmean1.time.data = maymean1.time.data\n",
    "DSST1mean = (maymean1 + aprilmean1 + marchmean1)/3\n",
    "\n",
    "#DSST2\n",
    "latrange2 = sst_anom.sel(lat = slice(10, -10)).lat\n",
    "weights2 = np.cos(latrange2*np.pi/180)\n",
    "\n",
    "marchdata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(250, 280), time = (sst_anom['time.month']==3))\n",
    "marchSST2 = marchdata2.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean2 = (marchSST2*weights2).mean({'lon', 'lat'})/weights2.mean()\n",
    "\n",
    "aprildata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(250, 280), time = (sst_anom['time.month']==4))\n",
    "aprilSST2 = aprildata2.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean2 = (aprilSST2*weights2).mean({'lon', 'lat'})/weights2.mean() \n",
    "\n",
    "maydata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(250, 280), time = (sst_anom['time.month']==5))\n",
    "maySST2 = maydata2.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean2 = (maySST2*weights2).mean({'lon', 'lat'})/weights2.mean()\n",
    "\n",
    "marchmean2.time.data = maymean2.time.data\n",
    "aprilmean2.time.data = maymean2.time.data\n",
    "DSST2mean = (maymean2 + aprilmean2 + marchmean2)/3\n",
    "\n",
    "EPToriginalmean = DSST1mean - DSST2mean\n",
    "#print(EPToriginalmean)\n",
    "EPTstd = EPToriginalmean.std()\n",
    "EPTmean = EPToriginalmean.mean()\n",
    "EPToriginalmean = (EPToriginalmean - EPTmean)/EPTstd\n",
    "print(EPToriginalmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (time: 88)>\n",
      "array([-0.080772, -0.225218,  0.491362, -1.248134, -0.645189,  1.300251,\n",
      "        0.555063, -0.063452,  0.173578, -1.033324,  0.176229, -0.491122,\n",
      "        0.298478, -0.402067, -0.491007,  0.679845, -0.333592, -0.454124,\n",
      "        0.117195,  0.033229,  0.077323, -0.115866, -0.46666 , -0.496127,\n",
      "        0.802483,  0.054825, -0.874542, -0.059067,  0.281781,  0.477808,\n",
      "       -0.82264 , -0.136874,  1.136438, -0.28846 ,  0.035331, -0.42295 ,\n",
      "       -0.066865,  0.939073,  1.160478, -0.305911,  0.670286, -0.268746,\n",
      "        0.992416,  0.256889, -0.598241, -0.291915,  1.099309, -0.964797,\n",
      "       -0.225345, -0.172757, -0.461868,  0.029544, -0.040109,  0.552491,\n",
      "       -0.469256,  0.50869 , -0.507958,  0.363192, -0.664474,  0.205008,\n",
      "       -0.462678,  0.378158,  0.317906,  0.277455, -0.084356,  0.401585,\n",
      "        0.088779, -0.242947, -0.210495, -0.623765, -0.269915,  0.539811,\n",
      "        0.317138, -1.218497,  0.403829, -0.35236 ,  0.11463 ,  0.386073,\n",
      "        0.341404, -0.589173,  0.223961, -0.406244, -0.842232,  0.359344,\n",
      "       -0.174583,  0.625735, -0.332464, -1.136646], dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n",
      "<xarray.DataArray (time: 88)>\n",
      "array([-0.087031, -0.349395,  0.952161, -2.207361, -1.112206,  2.42138 ,\n",
      "        1.067863, -0.055572,  0.374956, -1.817191,  0.379771, -0.832366,\n",
      "        0.601817, -0.670612, -0.832157,  1.29451 , -0.546239, -0.765166,\n",
      "        0.272546,  0.120034,  0.200123, -0.150773, -0.787937, -0.841457,\n",
      "        1.517263,  0.159261, -1.528789, -0.047607,  0.57149 ,  0.927541,\n",
      "       -1.434518, -0.188932,  2.12384 , -0.464264,  0.123852, -0.708544,\n",
      "       -0.061771,  1.765358,  2.167504, -0.49596 ,  1.277148, -0.428457,\n",
      "        1.862247,  0.526277, -1.026932, -0.470538,  2.056401, -1.692724,\n",
      "       -0.349625, -0.254107, -0.779232,  0.113341, -0.013173,  1.063192,\n",
      "       -0.792651,  0.983634, -0.862947,  0.71936 , -1.147233,  0.432044,\n",
      "       -0.780704,  0.746544,  0.637105,  0.563633, -0.09354 ,  0.789095,\n",
      "        0.220932, -0.381595, -0.322652, -1.073292, -0.43058 ,  1.040161,\n",
      "        0.635711, -2.153529,  0.793171, -0.580328,  0.267886,  0.76092 ,\n",
      "        0.679785, -1.010461,  0.466469, -0.6782  , -1.470103,  0.712371,\n",
      "       -0.257424,  1.196229, -0.54419 , -2.004861], dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n"
     ]
    }
   ],
   "source": [
    "DSST1 = (maymean1 - marchmean1)\n",
    "DSST2 = (maymean2 - marchmean2)\n",
    "\n",
    "EPToriginal = DSST1 - DSST2\n",
    "#print(EPToriginal)\n",
    "EPTstd = EPToriginal.std()\n",
    "EPTmean = EPToriginal.mean()\n",
    "EPToriginal = (EPToriginal - EPTmean)/EPTstd\n",
    "print(EPToriginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (time: 88)>\n",
      "array([-0.478318, -0.03203 , -0.200174, -0.085164, -1.184418, -0.303983,\n",
      "        0.671755,  0.593781,  1.207459,  0.479669,  0.102279, -0.760956,\n",
      "        0.272604,  0.417922, -0.554319, -0.447154,  0.880621, -0.279734,\n",
      "        0.571683, -0.1461  , -0.598452,  0.233263, -0.312774, -0.51441 ,\n",
      "       -0.689699,  0.03529 ,  0.058239, -0.111712, -0.191724,  0.819269,\n",
      "       -0.100841, -1.07182 , -0.128942,  0.185436, -0.470774,  0.397612,\n",
      "        1.007612,  0.119835, -0.350705, -0.122547, -0.287524, -0.575647,\n",
      "        0.822414,  0.490268, -0.690308, -0.752628,  0.79217 , -0.678447,\n",
      "        0.00836 ,  0.551998, -0.612676,  0.337533,  0.570257,  0.092181,\n",
      "        0.108381,  0.394022, -0.031021,  0.350358, -0.263635,  0.279484,\n",
      "       -0.29115 ,  0.12391 ,  0.658419,  0.317342, -0.963306,  0.507694,\n",
      "        0.614481, -0.059461, -0.368765, -1.122994,  0.249063,  0.100838,\n",
      "        0.540123, -0.631682, -1.766879,  0.42539 ,  0.405959, -0.035926,\n",
      "        0.335231,  0.003841,  0.352893,  0.10387 ,  0.268302, -0.011755,\n",
      "        0.04872 ,  0.714293, -0.013964, -0.424174], dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n",
      "    month    (time) float64 3.0 3.0 3.0 3.0 3.0 3.0 ... 3.0 3.0 3.0 3.0 3.0 3.0\n",
      "<xarray.DataArray (time: 88)>\n",
      "array([-0.888001, -0.057559, -0.370438, -0.15643 , -2.201896, -0.563602,\n",
      "        1.252027,  1.106936,  2.248853,  0.894599,  0.19236 , -1.413928,\n",
      "        0.509297,  0.779701, -1.029422, -0.830011,  1.640681, -0.518481,\n",
      "        1.065817, -0.269817, -1.111544,  0.436092, -0.579961, -0.95516 ,\n",
      "       -1.281333,  0.067708,  0.110412, -0.20583 , -0.354714,  1.526518,\n",
      "       -0.185601, -1.992376, -0.237889,  0.347097, -0.873963,  0.741908,\n",
      "        1.876983,  0.225029, -0.650541, -0.22599 , -0.532977, -1.069108,\n",
      "        1.532371,  0.914321, -1.282468, -1.398432,  1.476093, -1.260397,\n",
      "        0.017599,  1.029187, -1.138011,  0.630115,  1.063163,  0.173571,\n",
      "        0.203714,  0.735229, -0.055681,  0.653979, -0.488523,  0.522099,\n",
      "       -0.539723,  0.232611,  1.227213,  0.592545, -1.790455,  0.946746,\n",
      "        1.145454, -0.108602, -0.684147, -2.0876  ,  0.465493,  0.189678,\n",
      "        1.007091, -1.173376, -3.285725,  0.793597,  0.757441, -0.064809,\n",
      "        0.625832,  0.009189,  0.658696,  0.195321,  0.501293, -0.019832,\n",
      "        0.092699,  1.331183, -0.023942, -0.787251], dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n",
      "    month    (time) float64 3.0 3.0 3.0 3.0 3.0 3.0 ... 3.0 3.0 3.0 3.0 3.0 3.0\n"
     ]
    }
   ],
   "source": [
    "#EPT new\n",
    "#(10s-10n, 130-80w)\n",
    "#(10s-20n, 120-155e)\n",
    "\n",
    "#DSST!\n",
    "latrange1 = sst_anom.sel(lat = slice(20, -10)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "marchdata1 = sst_anom.sel(lat = slice(20, -10), lon = slice(120, 155), time = (sst_anom['time.month']==3))\n",
    "marchSST1 = marchdata1.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean1 = (marchSST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "aprildata1 = sst_anom.sel(lat = slice(20, -10), lon = slice(120, 155), time = (sst_anom['time.month']==4))\n",
    "aprilSST1 = aprildata1.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean1 = (aprilSST1*weights1).mean({'lon', 'lat'})/weights1.mean() \n",
    "\n",
    "maydata1 = sst_anom.sel(lat = slice(20, -10), lon = slice(120, 155), time = (sst_anom['time.month']==5))\n",
    "maySST1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = (maySST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "marchmean1.time.data = maymean1.time.data\n",
    "aprilmean1.time.data = maymean1.time.data\n",
    "DSST1new = (maymean1 + aprilmean1 + marchmean1)/3\n",
    "\n",
    "#DSST2\n",
    "latrange2 = sst_anom.sel(lat = slice(10, -10)).lat\n",
    "weights2 = np.cos(latrange2*np.pi/180)\n",
    "\n",
    "marchdata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(230, 280), time = (sst_anom['time.month']==3))\n",
    "marchSST2 = marchdata2.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean2 = (marchSST2*weights2).mean({'lon', 'lat'})/weights2.mean() \n",
    "\n",
    "aprildata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(230, 280), time = (sst_anom['time.month']==4))\n",
    "aprilSST2 = aprildata2.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean2 = (aprilSST2*weights2).mean({'lon', 'lat'})/weights2.mean() \n",
    "\n",
    "maydata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(230, 280), time = (sst_anom['time.month']==5))\n",
    "maySST2 = maydata2.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean2 = (maySST2*weights2).mean({'lon', 'lat'})/weights2.mean()\n",
    "\n",
    "marchmean2.time.data = maymean2.time.data\n",
    "aprilmean2.time.data = maymean2.time.data\n",
    "DSST2new = (maymean2 + aprilmean2 + marchmean2)/3\n",
    "\n",
    "EPT = DSST1new - DSST2new\n",
    "#print(EPT)\n",
    "EPTstd = EPT.std()\n",
    "EPTmean = EPT.mean()\n",
    "EPT = (EPT - EPTmean)/EPTstd\n",
    "print(EPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPT Original 0.4090731070587664\n",
      "DSST1 0.12665884513888592\n",
      "DSST2 -0.4011344478256808\n",
      "\n",
      "EPT Original Mean 0.31994607004780984\n",
      "DSST1 0.012677069713211699\n",
      "DSST2 -0.32672332406453375\n",
      "\n",
      "New EPT 0.37135127455627887\n",
      "DSST1 New 0.10499425764968058\n",
      "DSST2 New -0.3028914065363354\n"
     ]
    }
   ],
   "source": [
    "eptoriginal_subtraction = correlation(EPToriginal, precipa_jjas, dims='time')\n",
    "print(\"EPT Original\", eptoriginal_subtraction.data)\n",
    "ept_australia = correlation(DSST1, precipa_jjas, dims='time')\n",
    "print(\"DSST1\", ept_australia.data)\n",
    "ept_pacific = correlation(DSST2, precipa_jjas, dims='time')\n",
    "print(\"DSST2\", ept_pacific.data)\n",
    "\n",
    "print()\n",
    "eptoriginalmean_subtraction = correlation(EPToriginalmean, precipa_jjas, dims='time')\n",
    "print(\"EPT Original Mean\", eptoriginalmean_subtraction.data)\n",
    "ept_australiamean = correlation(DSST1mean, precipa_jjas, dims='time')\n",
    "print(\"DSST1\", ept_australiamean.data)\n",
    "ept_pacificmean = correlation(DSST2mean, precipa_jjas, dims='time')\n",
    "print(\"DSST2\", ept_pacificmean.data)\n",
    "\n",
    "print()\n",
    "ept_subtraction = correlation(EPT, precipa_jjas, dims='time')\n",
    "print(\"New EPT\", ept_subtraction.data)\n",
    "ept_australianew = correlation(DSST1new, precipa_jjas, dims='time')\n",
    "print(\"DSST1 New\", ept_australianew.data)\n",
    "ept_pacificnew = correlation(DSST2new, precipa_jjas, dims='time')\n",
    "print(\"DSST2 New\", ept_pacificnew.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (time: 88)>\n",
      "array([ 1.034446, -1.644795,  0.260865, -1.523214, -2.058889,  0.279677,\n",
      "        0.520603,  1.476613, -2.861686, -0.120737,  1.58951 , -0.388673,\n",
      "       -0.027112,  2.047418,  0.3757  , -2.200316,  0.330586,  0.319994,\n",
      "        0.059772, -0.089702,  0.473585,  0.404069, -0.20933 , -0.375415,\n",
      "        0.049273, -0.243741,  0.289054, -0.338636, -0.127177,  0.813011,\n",
      "        1.631568, -0.410525,  0.048517,  1.325921,  0.397832, -1.561584,\n",
      "       -0.733634,  0.632544, -1.80833 , -2.158612,  0.166518, -0.548333,\n",
      "        0.10629 ,  0.632596,  0.460435,  0.484698,  1.546964, -1.403212,\n",
      "       -0.420896,  0.689404, -0.674952,  2.048375,  0.677564, -0.983772,\n",
      "       -0.169912,  0.553684, -0.01093 ,  1.495744,  0.917114, -0.158445,\n",
      "       -0.07368 , -1.074418, -0.567051, -0.620656, -1.619773, -0.047012,\n",
      "        0.628906,  2.138351, -0.738455, -0.077431, -0.415636,  0.498731,\n",
      "       -1.319567, -0.649522,  2.0164  , -1.059239, -0.481311, -0.565523,\n",
      "        0.49364 ,  0.092773,  1.283855,  0.018563, -0.634944,  0.618393,\n",
      "        0.482863,  0.099684,  0.387322,  0.297353], dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n"
     ]
    }
   ],
   "source": [
    "#CP-ENSOpredictor\n",
    "\n",
    "#DSST1\n",
    "latrange1 = sst_anom.sel(lat = slice(-10, -25)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "aprildata1 = sst_anom.sel(lat = slice(-10, -25), lon = slice(170, 200), time = (sst_anom['time.month']==4))\n",
    "aprilSST1 = aprildata1.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean1 = (aprilSST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "maydata1 = sst_anom.sel(lat = slice(-10, -25), lon = slice(170, 200), time = (sst_anom['time.month']==5))\n",
    "maySST1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = (maySST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "aprilmean1.time.data = maymean1.time.data\n",
    "DSST1 = maymean1 - aprilmean1\n",
    "\n",
    "#DSST2\n",
    "latrange2 = sst_anom.sel(lat = slice(20, 5)).lat\n",
    "weights2 = np.cos(latrange2*np.pi/180)\n",
    "\n",
    "aprildata2 = sst_anom.sel(lat = slice(20, 5), lon = slice(180, 210), time = (sst_anom['time.month']==4))\n",
    "aprilSST2 = aprildata2.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean2 = (aprilSST2*weights2).mean({'lon', 'lat'})/weights2.mean()\n",
    "                          \n",
    "maydata2 = sst_anom.sel(lat = slice(20, 5), lon = slice(180, 210), time = (sst_anom['time.month']==5))\n",
    "maySST2 = maydata2.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean2 = (maySST2*weights2).mean({'lon', 'lat'})/weights2.mean()\n",
    "                          \n",
    "aprilmean2.time.data = maymean2.time.data\n",
    "DSST2 = maymean2 - aprilmean2\n",
    "\n",
    "CPToriginal = DSST1 - DSST2\n",
    "#print(CPToriginal)\n",
    "CPTstd = CPToriginal.std()\n",
    "CPTmean = CPToriginal.mean()\n",
    "CPToriginal = (CPToriginal - CPTmean)/CPTstd\n",
    "print(CPToriginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (time: 88)>\n",
      "array([ 0.413217, -1.412964,  0.18862 , -2.425838, -3.147323, -1.376669,\n",
      "       -0.267006,  0.612157, -0.192166, -0.676915,  0.821784, -1.016349,\n",
      "        0.295765,  3.117042,  0.491891, -0.238895,  0.157547,  0.023138,\n",
      "       -0.499815,  0.83123 ,  0.626021,  0.885561,  0.130674, -0.307108,\n",
      "        1.194109,  0.664761, -0.931261, -1.636097, -0.591374, -0.533841,\n",
      "        1.510118,  0.551406,  1.524788,  0.120483,  0.776971, -1.789856,\n",
      "        1.148034,  0.173274, -0.014265, -0.10438 , -0.744044,  0.688941,\n",
      "       -0.173456,  1.24826 ,  1.372423, -0.897227,  1.586309, -0.7768  ,\n",
      "       -0.347138,  1.005534, -0.708128,  0.772665,  0.725804, -0.292203,\n",
      "       -0.484095,  0.277428, -0.823857,  1.761318, -0.940902, -0.196139,\n",
      "       -0.882469, -0.715752,  0.15835 , -1.34445 , -1.414678, -0.159447,\n",
      "        0.913335,  1.914355, -0.691284,  0.222586, -0.113775, -0.125853,\n",
      "       -1.123544, -1.491947,  0.978121,  0.060592,  0.453439, -1.429334,\n",
      "        0.762192,  0.085753,  0.938102, -0.149568,  0.747719, -0.091073,\n",
      "       -0.089962,  0.901137,  0.39961 , -0.863321], dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n"
     ]
    }
   ],
   "source": [
    "#(55-5s, 175e-155w)\n",
    "latrange1 = sst_anom.sel(lat = slice(-5, -55)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "aprildata1 = sst_anom.sel(lat = slice(-5, -55), lon = slice(175, 205), time = (sst_anom['time.month']==4))\n",
    "aprilSST1 = aprildata1.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean1 = (aprilSST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "maydata1 = sst_anom.sel(lat = slice(-5, -55), lon = slice(175, 205), time = (sst_anom['time.month']==5))\n",
    "maySST1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = (maySST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "aprilmean1.time.data = maymean1.time.data\n",
    "DSST1new = maymean1 - aprilmean1\n",
    "\n",
    "CPT = DSST1new\n",
    "CPTstd = CPT.std()\n",
    "CPTmean = CPT.mean()\n",
    "CPT = (CPT - CPTmean)/CPTstd\n",
    "print(CPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPT Original 0.30216343741904705\n",
      "DSST1 0.3371017431515418\n",
      "DSST2 -0.06835848663702536\n",
      "\n",
      "CPT New 0.4316652726687996\n",
      "DSST 0.4316652410638617\n"
     ]
    }
   ],
   "source": [
    "cptoriginal_subtraction = correlation(CPToriginal, precipa_jjas, dims='time')\n",
    "print(\"CPT Original\", cptoriginal_subtraction.data)\n",
    "cpt_southpacific = correlation(DSST1, precipa_jjas, dims='time')\n",
    "print(\"DSST1\", cpt_southpacific.data)\n",
    "cpt_northpacific = correlation(DSST2, precipa_jjas, dims='time')\n",
    "print(\"DSST2\", cpt_northpacific.data)\n",
    "\n",
    "print()\n",
    "cptnew = correlation(CPT, precipa_jjas, dims='time')\n",
    "print(\"CPT New\", cptnew.data)\n",
    "cpt_pacific = correlation(DSST1new, precipa_jjas, dims='time')\n",
    "print(\"DSST\", cpt_pacific.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSH 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (time: 88)>\n",
      "array([-0.160115, -0.530665, -0.587413, -1.843401, -1.788555, -1.270153,\n",
      "       -2.416847, -0.284868, -1.137765, -1.446228, -1.358026, -2.107617,\n",
      "       -1.960992,  0.310206, -0.602675, -2.043644, -0.989641, -0.354539,\n",
      "       -0.568459, -0.210822, -0.243621, -0.166101, -0.30196 , -0.897021,\n",
      "       -0.68801 ,  0.004897, -0.919351,  0.050459,  0.106954,  1.509064,\n",
      "       -0.682947,  0.842869,  0.474949, -0.310772,  0.77388 ,  0.451246,\n",
      "        0.194778, -0.114258, -0.790516, -1.199903, -0.141202, -0.073532,\n",
      "       -0.353318,  1.469441, -0.647314, -0.674508,  0.623298, -0.009869,\n",
      "        0.248863, -0.547945, -0.071907,  0.794849,  0.612015,  0.191663,\n",
      "        0.773995,  0.775393,  0.721223,  0.129456, -0.687075, -0.052964,\n",
      "       -0.759927,  1.620226,  0.787352, -0.460351,  0.997016,  1.367667,\n",
      "        0.402568,  0.874843, -0.273629,  0.244379,  0.340428,  0.495529,\n",
      "        1.741729, -1.281774,  1.695221,  2.256278,  1.732105, -0.113447,\n",
      "        1.202087,  0.609768,  0.180042,  0.099426, -0.316158,  2.519642,\n",
      "        1.061588,  1.199829,  1.535483,  0.4191  ])\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n"
     ]
    }
   ],
   "source": [
    "#mega-ENSOpredictor\n",
    "\n",
    "#NPcalculation\n",
    "latrange1 = slp_anom.sel(lat = slice(-40, -10)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "marchdata1 = slp_anom.sel(lat = slice(-40, -10), lon = slice(200, 270), time = (slp_anom['time.month']==3))\n",
    "marchSLP1 = marchdata1.sel(time=slice('1900-03-01','2015-03-01'))\n",
    "marchmean1 = ((marchSLP1*weights1).mean({'lon', 'lat'})/weights1.mean())\n",
    "\n",
    "aprildata1 = slp_anom.sel(lat = slice(-40, -10), lon = slice(200, 270), time = (slp_anom['time.month']==4))\n",
    "aprilSLP1 = aprildata1.sel(time=slice('1900-04-01','2015-04-01'))\n",
    "aprilmean1 = ((aprilSLP1*weights1).mean({'lon', 'lat'})/weights1.mean())\n",
    "\n",
    "maydata1 = slp_anom.sel(lat = slice(-40, -10), lon = slice(200, 270), time = (slp_anom['time.month']==5))\n",
    "maySLP1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = ((maySLP1*weights1).mean({'lon', 'lat'})/weights1.mean())\n",
    "\n",
    "marchmean1.time.data = maymean1.time.data\n",
    "aprilmean1.time.data = maymean1.time.data\n",
    "NP = ((aprilmean1 + maymean1)/2)\n",
    "\n",
    "#SPcalculation\n",
    "latrange2 = slp_anom.sel(lat = slice(10, 30)).lat\n",
    "weights2 = np.cos(latrange2*np.pi/180)\n",
    "\n",
    "marchdata2 = slp_anom.sel(lat = slice(10, 30), lon = slice(180, 230), time = (slp_anom['time.month']==3))\n",
    "marchSLP2 = marchdata2.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean2 = ((marchSLP2*weights2).mean({'lon', 'lat'})/weights2.mean())\n",
    "\n",
    "aprildata2 = slp_anom.sel(lat = slice(10, 30), lon = slice(180, 230), time = (slp_anom['time.month']==4))\n",
    "aprilSLP2 = aprildata2.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean2 = ((aprilSLP2*weights2).mean({'lon', 'lat'})/weights2.mean())\n",
    "\n",
    "maydata2 = slp_anom.sel(lat = slice(10, 30), lon = slice(180, 230), time = (slp_anom['time.month']==5))\n",
    "maySLP2 = maydata2.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean2 = ((maySLP2*weights2).mean({'lon', 'lat'})/weights2.mean())\n",
    "\n",
    "marchmean2.time.data = maymean2.time.data\n",
    "aprilmean2.time.data = maymean2.time.data\n",
    "SP = ((aprilmean2 + maymean2)/2)\n",
    "\n",
    "NParea = (30*weights1.mean() * 60)\n",
    "SParea = (20*weights2.mean() * 50)\n",
    "PSHoriginal = ((NP * NParea) + (SP * SParea))/(NParea + SParea)\n",
    "#print(PSHoriginal)\n",
    "PSHstd = PSHoriginal.std()\n",
    "PSHmean = PSHoriginal.mean()\n",
    "PSHoriginal = (PSHoriginal - PSHmean)/PSHstd\n",
    "print(PSHoriginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (time: 88)>\n",
      "array([-6.831179e-01, -5.999682e-01, -1.160209e+00, -1.537893e+00,\n",
      "       -2.215940e+00, -1.213828e+00, -3.045280e+00, -4.760478e-01,\n",
      "       -9.106184e-01, -1.753336e+00, -9.360720e-01, -2.028238e+00,\n",
      "       -2.392695e+00,  3.682125e-01, -8.874249e-01, -1.644145e+00,\n",
      "       -7.992874e-01, -6.267059e-01, -4.443489e-01, -7.948714e-01,\n",
      "       -6.456407e-01,  4.098698e-01, -2.110797e-01, -8.572396e-01,\n",
      "       -4.771991e-01, -2.455378e-01, -8.047355e-01,  9.867723e-02,\n",
      "       -5.624620e-02,  1.334306e+00, -6.853132e-01,  5.835380e-01,\n",
      "        6.244053e-01, -7.223991e-01,  2.852268e-01,  8.773341e-01,\n",
      "        2.658506e-01, -2.050980e-03, -6.964100e-01, -1.391489e+00,\n",
      "        9.351112e-02,  4.056264e-02, -5.779046e-01,  1.078164e+00,\n",
      "       -3.805864e-01, -6.138678e-01,  1.062420e+00, -1.212729e-01,\n",
      "        2.888503e-01,  3.206597e-01,  1.283043e-01,  6.662065e-01,\n",
      "        7.779165e-01,  7.036594e-01,  9.616296e-01,  1.182424e+00,\n",
      "        7.116171e-01,  4.992048e-01, -1.843436e-01,  2.586927e-01,\n",
      "       -4.214042e-01,  1.280954e+00,  7.316259e-01,  1.337424e-01,\n",
      "        2.359699e-01,  1.294866e+00,  6.078602e-01,  9.326265e-01,\n",
      "       -3.172841e-01,  4.085003e-02,  1.683115e-01,  1.880258e-01,\n",
      "        1.487008e+00, -1.183332e+00,  1.326403e+00,  2.420038e+00,\n",
      "        1.460582e+00, -8.353990e-02,  6.931345e-01,  7.133196e-01,\n",
      "        5.639307e-01,  9.817589e-01,  5.084038e-02,  2.285758e+00,\n",
      "        9.874755e-01,  1.106062e+00,  1.254542e+00,  2.619746e-01])\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n",
      "    month    (time) float64 5.0 5.0 5.0 5.0 5.0 5.0 ... 5.0 5.0 5.0 5.0 5.0 5.0\n"
     ]
    }
   ],
   "source": [
    "NPmam = ((marchmean1 + aprilmean1 + maymean1)/3)\n",
    "SPmam = ((marchmean2 + aprilmean2 + maymean2)/3)\n",
    "\n",
    "PSHmam = ((NPmam * NParea) + (SPmam * SParea))/(NParea + SParea)\n",
    "PSHstd = PSHmam.std()\n",
    "PSHmean = PSHmam.mean()\n",
    "PSHmam = (PSHmam - PSHmean)/PSHstd\n",
    "print(PSHmam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSH Original 0.2511766012836855\n",
      "NP 0.212805324180741\n",
      "SP 0.21882287006708628\n",
      "\n",
      "PSH MAM 0.26171068608745524\n",
      "NP MAM 0.23816789300643842\n",
      "SP MAM 0.20010652961195954\n"
     ]
    }
   ],
   "source": [
    "pshoriginal_subtraction = correlation(PSHoriginal, precipa_jjas, dims='time')\n",
    "print(\"PSH Original\", pshoriginal_subtraction.data)\n",
    "psh_northpacific = correlation(NP, precipa_jjas, dims='time')\n",
    "print(\"NP\", psh_northpacific.data)\n",
    "psh_southpacific = correlation(SP, precipa_jjas, dims='time')\n",
    "print(\"SP\", psh_southpacific.data)\n",
    "\n",
    "print()\n",
    "pshmam_subtraction = correlation(PSHmam, precipa_jjas, dims='time')\n",
    "print(\"PSH MAM\", pshmam_subtraction.data)\n",
    "pshmam_northpacific = correlation(NPmam, precipa_jjas, dims='time')\n",
    "print(\"NP MAM\", pshmam_northpacific.data)\n",
    "pshmam_southpacific = correlation(SPmam, precipa_jjas, dims='time')\n",
    "print(\"SP MAM\", pshmam_southpacific.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSH 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xarrayenv2",
   "language": "python",
   "name": "xarrayenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
