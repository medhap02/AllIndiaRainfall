{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import cartopy as cp\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import cftime\n",
    "import dateutil\n",
    "import dask\n",
    "#Use the 2 lines below if the notebook has a dark theme (to make labelling visible):\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='chesterish', context='notebook', ticks=True, grid=False)\n",
    "import matplotlib.pyplot as plt\n",
    "#The following code resets the default plot size so you don't have to fiddle with figsize every time\"\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 16\n",
    "fig_size[1] = 8\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HDF5_USE_FILE_LOCKING=FALSE\n"
     ]
    }
   ],
   "source": [
    "#Need the following line to avoid hdf5 issues that prevent opening thee file\n",
    "# https://stackoverflow.com/questions/49317927/errno-101-netcdf-hdf-error-when-opening-netcdf-file\n",
    "%env HDF5_USE_FILE_LOCKING=FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load AIRI data \n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import num2date, date2num\n",
    "dataset_file = \"pALLIN.nc\"\n",
    "airi_dat = xr.open_dataset(dataset_file, decode_times=False)\n",
    "units, reference_date = airi_dat.time.attrs['units'].split('since')\n",
    "airi_dat['time'] = pd.date_range(start=reference_date, periods=airi_dat.sizes['time'], freq='MS')\n",
    "#This file's calendar isn't recognized when using xr.open_dataset. The above workaround is from: \n",
    "#https://stackoverflow.com/questions/55648630/how-to-decode-the-time-variable-while-using-xarray-to-load-a-netcdf-file\n",
    "# \"M\" means \"month end frequency\" (see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 1752)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1871-02-01 1871-03-01 ... 2017-01-01\n",
       "Data variables:\n",
       "    precip   (time) float32 ...\n",
       "Attributes:\n",
       "    title:        \n",
       "    description:  All-India Rainfall\n",
       "    scripturl01:  https://climexp.knmi.nl/getindices.cgi?STATION=All-India_Ra...\n",
       "    comment:      \n",
       "    institution:  KNMI Climate Explorer\n",
       "    scripturl02:  https://climexp.knmi.nl/dat2nc.cgi?id=$id&station=All-India...\n",
       "    history:       2020-04-02  2:43:20 bin/dat2nc data/pALLIN.dat p All-India...\n",
       "    Conventions:  CF-1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airi_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip = airi_dat['precip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load SST data\n",
    "dataset_url = \"https://psl.noaa.gov/thredds/dodsC/Datasets/noaa.ersst.v5/sst.mnmean.nc\"\n",
    "sst_dat = xr.open_dataset(dataset_url)\n",
    "sst = sst_dat['sst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/medhap02/.conda/envs/xarrayenv2/lib/python3.7/site-packages/xarray/core/nanops.py:160: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'sst' (time: 1752, lat: 89, lon: 180)>\n",
       "array([[[1.788139e-06, 1.788139e-06, ..., 1.788139e-06, 1.788139e-06],\n",
       "        [1.788139e-06, 1.788139e-06, ..., 1.788139e-06, 1.788139e-06],\n",
       "        ...,\n",
       "        [         nan,          nan, ...,          nan,          nan],\n",
       "        [         nan,          nan, ...,          nan,          nan]],\n",
       "\n",
       "       [[1.788139e-06, 1.788139e-06, ..., 1.788139e-06, 1.788139e-06],\n",
       "        [1.788139e-06, 1.788139e-06, ..., 1.788139e-06, 1.788139e-06],\n",
       "        ...,\n",
       "        [         nan,          nan, ...,          nan,          nan],\n",
       "        [         nan,          nan, ...,          nan,          nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[3.152323e-02, 2.609873e-02, ..., 2.140296e-02, 3.102016e-02],\n",
       "        [2.697122e-02, 1.542413e-02, ..., 1.046002e-02, 2.427316e-02],\n",
       "        ...,\n",
       "        [         nan,          nan, ...,          nan,          nan],\n",
       "        [         nan,          nan, ...,          nan,          nan]],\n",
       "\n",
       "       [[1.788139e-06, 1.788139e-06, ..., 1.788139e-06, 1.788139e-06],\n",
       "        [1.788139e-06, 1.788139e-06, ..., 1.788139e-06, 1.788139e-06],\n",
       "        ...,\n",
       "        [         nan,          nan, ...,          nan,          nan],\n",
       "        [         nan,          nan, ...,          nan,          nan]]],\n",
       "      dtype=float32)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 88.0 86.0 84.0 82.0 80.0 ... -82.0 -84.0 -86.0 -88.0\n",
       "  * lon      (lon) float32 0.0 2.0 4.0 6.0 8.0 ... 350.0 352.0 354.0 356.0 358.0\n",
       "  * time     (time) datetime64[ns] 1871-02-01 1871-03-01 ... 2017-01-01\n",
       "    month    (time) int64 2 3 4 5 6 7 8 9 10 11 12 ... 3 4 5 6 7 8 9 10 11 12 1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Slice SST data to the same duration as precip and calculate monthly anomalies\n",
    "sst_subset = sst.sel(time=slice('1871-01-30','2017-01-01'))\n",
    "sst_clim = sst_subset.groupby('time.month').mean('time')\n",
    "sst_anomfull = sst_subset.groupby(\"time.month\")-sst_clim\n",
    "sst_anomfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 89, lon: 180, time: 1056)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-01-01 1900-02-01 ... 2015-12-01\n",
      "  * lat      (lat) float32 88.0 86.0 84.0 82.0 80.0 ... -82.0 -84.0 -86.0 -88.0\n",
      "  * lon      (lon) float32 0.0 2.0 4.0 6.0 8.0 ... 350.0 352.0 354.0 356.0 358.0\n",
      "    month    (time) float64 1.0 2.0 3.0 4.0 5.0 6.0 ... 8.0 9.0 10.0 11.0 12.0\n",
      "Data variables:\n",
      "    sst      (time, lat, lon) float32 1.7881393e-06 1.7881393e-06 ... nan nan\n"
     ]
    }
   ],
   "source": [
    "sst_subset1 = sst_anomfull.sel(time=slice('1900-01-01','1901-12-31'))\n",
    "sst_subset2 = sst_anomfull.sel(time=slice('1903-01-01','1906-12-31'))\n",
    "sst_subset3 = sst_anomfull.sel(time=slice('1908-01-01','1911-12-31'))\n",
    "sst_subset4 = sst_anomfull.sel(time=slice('1913-01-01','1913-12-31'))\n",
    "sst_subset5 = sst_anomfull.sel(time=slice('1915-01-01','1918-12-31'))\n",
    "sst_subset6 = sst_anomfull.sel(time=slice('1920-01-01','1921-12-31'))\n",
    "sst_subset7 = sst_anomfull.sel(time=slice('1923-01-01','1927-12-31'))\n",
    "sst_subset8 = sst_anomfull.sel(time=slice('1929-01-01','1931-12-31'))\n",
    "sst_subset9 = sst_anomfull.sel(time=slice('1934-01-01','1939-12-31'))\n",
    "sst_subset10 = sst_anomfull.sel(time=slice('1941-01-01','1948-12-31'))\n",
    "sst_subset11 = sst_anomfull.sel(time=slice('1951-01-01','1955-12-31'))\n",
    "sst_subset12 = sst_anomfull.sel(time=slice('1957-01-01','1958-12-31'))\n",
    "sst_subset13 = sst_anomfull.sel(time=slice('1960-01-01','1962-12-31'))\n",
    "sst_subset13 = sst_anomfull.sel(time=slice('1964-01-01','1965-12-31'))\n",
    "sst_subset14 = sst_anomfull.sel(time=slice('1967-01-01','1971-12-31'))\n",
    "sst_subset15 = sst_anomfull.sel(time=slice('1973-01-01','1976-12-31'))\n",
    "sst_subset16 = sst_anomfull.sel(time=slice('1978-01-01','1979-12-31'))\n",
    "sst_subset17 = sst_anomfull.sel(time=slice('1981-01-01','1982-12-31'))\n",
    "sst_subset18 = sst_anomfull.sel(time=slice('1984-01-01','1991-12-31'))\n",
    "sst_subset19 = sst_anomfull.sel(time=slice('1993-01-01','1998-12-31'))\n",
    "sst_subset20 = sst_anomfull.sel(time=slice('2000-01-01','2002-12-31'))\n",
    "sst_subset21 = sst_anomfull.sel(time=slice('2004-01-01','2006-12-31'))\n",
    "sst_subset22 = sst_anomfull.sel(time=slice('2008-01-01','2010-12-31'))\n",
    "sst_subset23 = sst_anomfull.sel(time=slice('2012-01-01','2015-12-31'))\n",
    "\n",
    "sst_anomtemp = xr.merge([sst_subset1, sst_subset2, sst_subset3, sst_subset4, sst_subset5, \n",
    "                   sst_subset6, sst_subset7, sst_subset8, sst_subset9, sst_subset10, \n",
    "                   sst_subset11, sst_subset12, sst_subset13, sst_subset14, sst_subset15, \n",
    "                   sst_subset16, sst_subset17, sst_subset18, sst_subset19, sst_subset20, \n",
    "                   sst_subset21, sst_subset22, sst_subset23])\n",
    "#sst_anom = xr.Dataset.to_array(sst_anomtemp).drop('variable')\n",
    "print(sst_anomtemp)\n",
    "sst_anom = sst_anomtemp['sst']\n",
    "#1902, 1907, 1912, 1914, 1919, 1922, 1928, 1932, 1933, 1940\n",
    "#1949, 1950, 1956, 1959, 1963, 1966, 1972, 1977, 1980, 1983\n",
    "#1992, 1999, 2003, 2007, 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get precip anomalies\n",
    "precip_clim = precip.groupby(\"time.month\").mean(\"time\")\n",
    "precip_anomfull = precip.groupby(\"time.month\") - precip_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'precip' (time: 1056)>\n",
      "array([ -9.166439,   4.535616,  -5.745206, ..., -44.439735, -40.930824,\n",
      "        13.444523], dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-01-01 1900-02-01 ... 2015-12-01\n",
      "    month    (time) float64 1.0 2.0 3.0 4.0 5.0 6.0 ... 8.0 9.0 10.0 11.0 12.0\n"
     ]
    }
   ],
   "source": [
    "precip_subset1 = precip_anomfull.sel(time=slice('1900-01-01','1901-12-31'))\n",
    "precip_subset2 = precip_anomfull.sel(time=slice('1903-01-01','1906-12-31'))\n",
    "precip_subset3 = precip_anomfull.sel(time=slice('1908-01-01','1911-12-31'))\n",
    "precip_subset4 = precip_anomfull.sel(time=slice('1913-01-01','1913-12-31'))\n",
    "precip_subset5 = precip_anomfull.sel(time=slice('1915-01-01','1918-12-31'))\n",
    "precip_subset6 = precip_anomfull.sel(time=slice('1920-01-01','1921-12-31'))\n",
    "precip_subset7 = precip_anomfull.sel(time=slice('1923-01-01','1927-12-31'))\n",
    "precip_subset8 = precip_anomfull.sel(time=slice('1929-01-01','1931-12-31'))\n",
    "precip_subset9 = precip_anomfull.sel(time=slice('1934-01-01','1939-12-31'))\n",
    "precip_subset10 = precip_anomfull.sel(time=slice('1941-01-01','1948-12-31'))\n",
    "precip_subset11 = precip_anomfull.sel(time=slice('1951-01-01','1955-12-31'))\n",
    "precip_subset12 = precip_anomfull.sel(time=slice('1957-01-01','1958-12-31'))\n",
    "precip_subset13 = precip_anomfull.sel(time=slice('1960-01-01','1962-12-31'))\n",
    "precip_subset13 = precip_anomfull.sel(time=slice('1964-01-01','1965-12-31'))\n",
    "precip_subset14 = precip_anomfull.sel(time=slice('1967-01-01','1971-12-31'))\n",
    "precip_subset15 = precip_anomfull.sel(time=slice('1973-01-01','1976-12-31'))\n",
    "precip_subset16 = precip_anomfull.sel(time=slice('1978-01-01','1979-12-31'))\n",
    "precip_subset17 = precip_anomfull.sel(time=slice('1981-01-01','1982-12-31'))\n",
    "precip_subset18 = precip_anomfull.sel(time=slice('1984-01-01','1991-12-31'))\n",
    "precip_subset19 = precip_anomfull.sel(time=slice('1993-01-01','1998-12-31'))\n",
    "precip_subset20 = precip_anomfull.sel(time=slice('2000-01-01','2002-12-31'))\n",
    "precip_subset21 = precip_anomfull.sel(time=slice('2004-01-01','2006-12-31'))\n",
    "precip_subset22 = precip_anomfull.sel(time=slice('2008-01-01','2010-12-31'))\n",
    "precip_subset23 = precip_anomfull.sel(time=slice('2012-01-01','2015-12-31'))\n",
    "\n",
    "precip_anom = xr.merge([precip_subset1, precip_subset2, precip_subset3, precip_subset4, precip_subset5, \n",
    "                   precip_subset6, precip_subset7, precip_subset8, precip_subset9, precip_subset10, \n",
    "                   precip_subset11, precip_subset12, precip_subset13, precip_subset14, precip_subset15, \n",
    "                   precip_subset16, precip_subset17, precip_subset18, precip_subset19, precip_subset20, \n",
    "                   precip_subset21, precip_subset22, precip_subset23])\n",
    "precip_anomtemp = xr.Dataset.to_array(precip_anom)\n",
    "precip_anom = precip_anom['precip']\n",
    "print(precip_anom)\n",
    "#1902, 1907, 1912, 1914, 1919, 1922, 1928, 1932, 1933, 1940\n",
    "#1949, 1950, 1956, 1959, 1963, 1966, 1972, 1977, 1980, 1983\n",
    "#1992, 1999, 2003, 2007, 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x, y, dims=None):\n",
    "    return xr.dot(x - x.mean(dims), y - y.mean(dims), dims=dims) / x.count(dims)\n",
    "\n",
    "def correlation(x, y, dims=None):\n",
    "    return covariance(x, y, dims) / (x.std(dims) * y.std(dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (time: 88)>\n",
      "array([-0.08078 , -0.225189,  0.491364, -1.248138, -0.645172,  1.300232,\n",
      "        0.555054, -0.063446,  0.173615, -1.033325,  0.176208, -0.491119,\n",
      "        0.298462, -0.402069, -0.490997,  0.679871, -0.333588, -0.454132,\n",
      "        0.117188,  0.033234,  0.077301, -0.115845, -0.466675, -0.496155,\n",
      "        0.80249 ,  0.05481 , -0.874542, -0.059082,  0.281799,  0.477783,\n",
      "       -0.822632, -0.136871,  1.136444, -0.288483,  0.035339, -0.422943,\n",
      "       -0.066864,  0.939056,  1.160461, -0.305908,  0.670288, -0.268768,\n",
      "        0.992371,  0.256897, -0.598236, -0.291931,  1.099304, -0.964783,\n",
      "       -0.225372, -0.172791, -0.461853,  0.029572, -0.0401  ,  0.552521,\n",
      "       -0.469269,  0.508698, -0.507965,  0.36322 , -0.66449 ,  0.204987,\n",
      "       -0.462677,  0.378143,  0.317871,  0.277466, -0.084381,  0.401581,\n",
      "        0.088776, -0.24292 , -0.21051 , -0.623779, -0.269897,  0.539825,\n",
      "        0.317139, -1.218475,  0.403839, -0.352356,  0.114624,  0.386108,\n",
      "        0.3414  , -0.589172,  0.223938, -0.406219, -0.842224,  0.359344,\n",
      "       -0.174591,  0.625763, -0.332489, -1.136658], dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n",
      "<xarray.DataArray (time: 88)>\n",
      "array([-0.087043, -0.349341,  0.952167, -2.20737 , -1.112175,  2.421352,\n",
      "        1.067851, -0.055559,  0.375025, -1.817195,  0.379737, -0.832362,\n",
      "        0.601791, -0.670616, -0.83214 ,  1.294561, -0.54623 , -0.76518 ,\n",
      "        0.272534,  0.120045,  0.200086, -0.150733, -0.787962, -0.841508,\n",
      "        1.517281,  0.159234, -1.52879 , -0.047632,  0.571526,  0.927501,\n",
      "       -1.434503, -0.188925,  2.123857, -0.464303,  0.123869, -0.70853 ,\n",
      "       -0.061767,  1.765332,  2.167481, -0.495954,  1.277156, -0.428495,\n",
      "        1.86217 ,  0.526295, -1.026923, -0.470567,  2.056398, -1.692698,\n",
      "       -0.349673, -0.254166, -0.779204,  0.113393, -0.013155,  1.06325 ,\n",
      "       -0.792674,  0.983652, -0.862959,  0.719415, -1.147262,  0.432008,\n",
      "       -0.780701,  0.74652 ,  0.637045,  0.563655, -0.093584,  0.789091,\n",
      "        0.220928, -0.381546, -0.322678, -1.073318, -0.430546,  1.040191,\n",
      "        0.635715, -2.153492,  0.793193, -0.580319,  0.267878,  0.760987,\n",
      "        0.679782, -1.01046 ,  0.46643 , -0.678154, -1.470089,  0.712375,\n",
      "       -0.257437,  1.196283, -0.544234, -2.004883], dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n"
     ]
    }
   ],
   "source": [
    "#EPT original\n",
    "\n",
    "#DSST1\n",
    "latrange1 = sst_anom.sel(lat = slice(5, -20)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "marchdata1 = sst_anom.sel(lat = slice(5, -20), lon = slice(150, 170), time = (sst_anom['time.month']==3))\n",
    "marchSST1 = marchdata1.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean1 = (marchSST1*weights1).mean({'lon', 'lat'})/weights1.mean() - 273.15\n",
    "\n",
    "maydata1 = sst_anom.sel(lat = slice(5, -20), lon = slice(150, 170), time = (sst_anom['time.month']==5))\n",
    "maySST1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = (maySST1*weights1).mean({'lon', 'lat'})/weights1.mean() - 273.15\n",
    "\n",
    "marchmean1.time.data = maymean1.time.data\n",
    "DSST1 = maymean1 - marchmean1\n",
    "\n",
    "#DSST2\n",
    "latrange2 = sst_anom.sel(lat = slice(10, -10)).lat\n",
    "weights2 = np.cos(latrange2*np.pi/180)\n",
    "\n",
    "marchdata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(250, 280), time = (sst_anom['time.month']==3))\n",
    "marchSST2 = marchdata2.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean2 = (marchSST2*weights2).mean({'lon', 'lat'})/weights2.mean() - 273.15\n",
    "\n",
    "maydata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(250, 280), time = (sst_anom['time.month']==5))\n",
    "maySST2 = maydata2.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean2 = (maySST2*weights2).mean({'lon', 'lat'})/weights2.mean() - 273.15\n",
    "\n",
    "marchmean2.time.data = maymean2.time.data\n",
    "DSST2 = (maymean2 - marchmean2)\n",
    "\n",
    "EPToriginal = DSST1 - DSST2\n",
    "print(EPToriginal)\n",
    "EPTstd = EPToriginal.std()\n",
    "EPTmean = EPToriginal.mean()\n",
    "EPToriginal = (EPToriginal - EPTmean)/EPTstd\n",
    "print(EPToriginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (time: 88)>\n",
      "array([ 0.322673,  0.021907,  0.746459, -0.602096, -0.800205,  0.789433,\n",
      "        0.241033,  0.391996, -0.191677, -0.774949, -0.173333, -0.446443,\n",
      "        0.472685, -1.645516, -0.655767,  0.241526, -0.762896, -0.309169,\n",
      "        0.190367, -0.241651,  0.237913, -0.349789, -0.453872, -0.326606,\n",
      "        0.489138, -0.20656 , -0.573685,  0.089507,  0.141588,  0.002037,\n",
      "       -0.728022, -0.018712,  0.540013, -0.785735,  0.518458, -0.733088,\n",
      "       -0.465441,  0.453669,  0.105734, -0.217126,  0.417271, -0.178159,\n",
      "        0.631829,  0.366409, -0.345678, -0.249477,  0.911481, -0.538432,\n",
      "       -0.10534 ,  0.078811, -0.182488,  0.332907, -0.094644,  1.031955,\n",
      "       -0.056144,  0.432659, -0.693379,  0.50747 , -0.299264,  0.554705,\n",
      "       -0.537509,  0.605848, -0.00805 ,  0.523607,  0.321832,  0.579125,\n",
      "       -0.089401, -0.051927, -0.18763 , -0.4551  , -0.130303,  0.667913,\n",
      "        0.522171, -0.689699,  0.205306, -0.131709,  0.073122,  0.188038,\n",
      "        0.167905, -0.205882, -0.224118, -0.744714, -0.940743,  0.5312  ,\n",
      "       -0.264262,  0.66613 , -0.030272, -0.699871], dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n",
      "<xarray.DataArray (time: 88)>\n",
      "array([ 0.72531 ,  0.119301,  1.579186, -1.137989, -1.537154,  1.665774,\n",
      "        0.560814,  0.864986, -0.311044, -1.486266, -0.274083, -0.824367,\n",
      "        1.027565, -3.240353, -1.246128,  0.561807, -1.461981, -0.547776,\n",
      "        0.458728, -0.411736,  0.554527, -0.629621, -0.839334, -0.582909,\n",
      "        1.060716, -0.341032, -1.080744,  0.255508,  0.360445,  0.079267,\n",
      "       -1.391714,  0.03746 ,  1.163222, -1.507998,  1.119791, -1.401921,\n",
      "       -0.862644,  0.989249,  0.288203, -0.36232 ,  0.915912, -0.283806,\n",
      "        1.348221,  0.813431, -0.621338, -0.427504,  1.911686, -1.009713,\n",
      "       -0.137086,  0.233957, -0.292529,  0.745929, -0.115535,  2.154426,\n",
      "       -0.037962,  0.946916, -1.321912,  1.097654, -0.527818,  1.192825,\n",
      "       -1.007853,  1.295873,  0.058942,  1.130167,  0.723614,  1.242028,\n",
      "       -0.10497 , -0.029464, -0.302889, -0.841809, -0.187382,  1.420926,\n",
      "        1.127272, -1.314497,  0.488828, -0.190216,  0.222493,  0.454036,\n",
      "        0.413469, -0.339666, -0.376409, -1.425346, -1.820322,  1.145466,\n",
      "       -0.457293,  1.417333,  0.014168, -1.334994], dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n"
     ]
    }
   ],
   "source": [
    "#EPT new\n",
    "#(10s-10n, 130-80w)\n",
    "#(10s-20n, 120-155e)\n",
    "\n",
    "#DSST!\n",
    "latrange1 = sst_anom.sel(lat = slice(20, -10)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "marchdata1 = sst_anom.sel(lat = slice(20, -10), lon = slice(120, 155), time = (sst_anom['time.month']==3))\n",
    "marchSST1 = marchdata1.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean1 = (marchSST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "maydata1 = sst_anom.sel(lat = slice(20, -10), lon = slice(120, 155), time = (sst_anom['time.month']==5))\n",
    "maySST1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = (maySST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "marchmean1.time.data = maymean1.time.data\n",
    "DSST1 = maymean1 - marchmean1\n",
    "\n",
    "#DSST2\n",
    "latrange2 = sst_anom.sel(lat = slice(10, -10)).lat\n",
    "weights2 = np.cos(latrange2*np.pi/180)\n",
    "\n",
    "marchdata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(230, 280), time = (sst_anom['time.month']==3))\n",
    "marchSST2 = marchdata2.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean2 = (marchSST2*weights2).mean({'lon', 'lat'})/weights2.mean() \n",
    "\n",
    "maydata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(230, 280), time = (sst_anom['time.month']==5))\n",
    "maySST2 = maydata2.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean2 = (maySST2*weights2).mean({'lon', 'lat'})/weights2.mean()\n",
    "\n",
    "marchmean2.time.data = maymean2.time.data\n",
    "DSST2 = (maymean2 - marchmean2)\n",
    "\n",
    "EPT = DSST1 - DSST2\n",
    "print(EPT)\n",
    "EPTstd = EPT.std()\n",
    "EPTmean = EPT.mean()\n",
    "EPT = (EPT - EPTmean)/EPTstd\n",
    "print(EPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipa_june = precip_anom[junes]\n",
    "precipa_july = precip_anom[julys]\n",
    "precipa_august = precip_anom[augusts]\n",
    "precipa_september = precip_anom[septembers]\n",
    "\n",
    "precipa_july.time.data = precipa_june.time.data\n",
    "precipa_august.time.data = precipa_june.time.data\n",
    "precipa_september.time.data = precipa_june.time.data\n",
    "\n",
    "precipa_jjas = (precipa_june + precipa_july + precipa_august + precipa_september)\n",
    "precipa_jjas.time.data = EPT.time.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ept original <xarray.DataArray ()>\n",
      "array(0.409076)\n",
      "new ept <xarray.DataArray ()>\n",
      "array(0.286874)\n"
     ]
    }
   ],
   "source": [
    "eptoriginal_subtraction = correlation(EPToriginal, precipa_jjas, dims='time')\n",
    "print(\"ept original\", eptoriginal_subtraction)\n",
    "\n",
    "ept_subtraction = correlation(EPT, precipa_jjas, dims='time')\n",
    "print(\"new ept\", ept_subtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xarrayenv2",
   "language": "python",
   "name": "xarrayenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
