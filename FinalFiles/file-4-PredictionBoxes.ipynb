{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import cartopy as cp\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import cftime\n",
    "import dateutil\n",
    "import dask\n",
    "#Use the 2 lines below if the notebook has a dark theme (to make labelling visible):\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='chesterish', context='notebook', ticks=True, grid=False)\n",
    "import matplotlib.pyplot as plt\n",
    "#The following code resets the default plot size so you don't have to fiddle with figsize every time\"\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 16\n",
    "fig_size[1] = 8\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HDF5_USE_FILE_LOCKING=FALSE\n"
     ]
    }
   ],
   "source": [
    "#Need the following line to avoid hdf5 issues that prevent opening thee file\n",
    "# https://stackoverflow.com/questions/49317927/errno-101-netcdf-hdf-error-when-opening-netcdf-file\n",
    "%env HDF5_USE_FILE_LOCKING=FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import num2date, date2num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x, y, dims=None):\n",
    "    return xr.dot(x - x.mean(dims), y - y.mean(dims), dims=dims) / x.count(dims)\n",
    "\n",
    "def correlation(x, y, dims=None):\n",
    "    return covariance(x, y, dims) / (x.std(dims) * y.std(dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIRI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = \"pALLIN.nc\"\n",
    "airi_dat = xr.open_dataset(dataset_file, decode_times=False)\n",
    "units, reference_date = airi_dat.time.attrs['units'].split('since')\n",
    "airi_dat['time'] = pd.date_range(start=reference_date, periods=airi_dat.sizes['time'], freq='MS')\n",
    "#This file's calendar isn't recognized when using xr.open_dataset. The above workaround is from: \n",
    "#https://stackoverflow.com/questions/55648630/how-to-decode-the-time-variable-while-using-xarray-to-load-a-netcdf-file\n",
    "# \"M\" means \"month end frequency\" (see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)\n",
    "precip = airi_dat['precip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get precip anomalies\n",
    "precip_clim = precip.groupby(\"time.month\").mean(\"time\")\n",
    "precip_anomfull = precip.groupby(\"time.month\") - precip_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_jjas(month):\n",
    "    return (month >= 6) & (month <= 9)\n",
    "precip = precip_anomfull.sel(time=is_jjas(precip_anomfull['time.month'])).groupby('time.year').sum(dim='time')\n",
    "\n",
    "monthtime = pd.date_range('1871-01-01', freq='Y', periods=146)\n",
    "precip['year'] = monthtime\n",
    "precip = precip.rename({'year': 'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_subset1 = precip.sel(time=slice('1900-01-01','1901-12-31'))\n",
    "precip_subset2 = precip.sel(time=slice('1903-01-01','1906-12-31'))\n",
    "precip_subset3 = precip.sel(time=slice('1908-01-01','1911-12-31'))\n",
    "precip_subset4 = precip.sel(time=slice('1913-01-01','1913-12-31'))\n",
    "precip_subset5 = precip.sel(time=slice('1915-01-01','1918-12-31'))\n",
    "precip_subset6 = precip.sel(time=slice('1920-01-01','1921-12-31'))\n",
    "precip_subset7 = precip.sel(time=slice('1923-01-01','1927-12-31'))\n",
    "precip_subset8 = precip.sel(time=slice('1929-01-01','1931-12-31'))\n",
    "precip_subset9 = precip.sel(time=slice('1934-01-01','1939-12-31'))\n",
    "precip_subset10 = precip.sel(time=slice('1941-01-01','1948-12-31'))\n",
    "precip_subset11 = precip.sel(time=slice('1951-01-01','1955-12-31'))\n",
    "precip_subset12 = precip.sel(time=slice('1957-01-01','1958-12-31'))\n",
    "precip_subset13 = precip.sel(time=slice('1960-01-01','1962-12-31'))\n",
    "precip_subset13 = precip.sel(time=slice('1964-01-01','1965-12-31'))\n",
    "precip_subset14 = precip.sel(time=slice('1967-01-01','1971-12-31'))\n",
    "precip_subset15 = precip.sel(time=slice('1973-01-01','1976-12-31'))\n",
    "precip_subset16 = precip.sel(time=slice('1978-01-01','1979-12-31'))\n",
    "precip_subset17 = precip.sel(time=slice('1981-01-01','1982-12-31'))\n",
    "precip_subset18 = precip.sel(time=slice('1984-01-01','1991-12-31'))\n",
    "precip_subset19 = precip.sel(time=slice('1993-01-01','1998-12-31'))\n",
    "precip_subset20 = precip.sel(time=slice('2000-01-01','2002-12-31'))\n",
    "precip_subset21 = precip.sel(time=slice('2004-01-01','2006-12-31'))\n",
    "precip_subset22 = precip.sel(time=slice('2008-01-01','2010-12-31'))\n",
    "precip_subset23 = precip.sel(time=slice('2012-01-01','2015-12-31'))\n",
    "\n",
    "precip_anom = xr.merge([precip_subset1, precip_subset2, precip_subset3, precip_subset4, precip_subset5, \n",
    "                   precip_subset6, precip_subset7, precip_subset8, precip_subset9, precip_subset10, \n",
    "                   precip_subset11, precip_subset12, precip_subset13, precip_subset14, precip_subset15, \n",
    "                   precip_subset16, precip_subset17, precip_subset18, precip_subset19, precip_subset20, \n",
    "                   precip_subset21, precip_subset22, precip_subset23])\n",
    "precip_anomtemp = xr.Dataset.to_array(precip_anom)\n",
    "precipa_jjas = precip_anom['precip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://psl.noaa.gov/thredds/dodsC/Datasets/noaa.ersst.v5/sst.mnmean.nc\"\n",
    "sst_dat = xr.open_dataset(dataset_url)\n",
    "sst = sst_dat['sst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/medhap02/.conda/envs/xarrayenv2/lib/python3.7/site-packages/xarray/core/nanops.py:160: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "#Slice SST data to the same duration as precip and calculate monthly anomalies\n",
    "sst_subset = sst.sel(time=slice('1871-01-30','2017-01-01'))\n",
    "sst_clim = sst_subset.groupby('time.month').mean('time')\n",
    "sst_anomfull = sst_subset.groupby(\"time.month\")-sst_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_subset1 = sst_anomfull.sel(time=slice('1900-01-01','1901-12-31'))\n",
    "sst_subset2 = sst_anomfull.sel(time=slice('1903-01-01','1906-12-31'))\n",
    "sst_subset3 = sst_anomfull.sel(time=slice('1908-01-01','1911-12-31'))\n",
    "sst_subset4 = sst_anomfull.sel(time=slice('1913-01-01','1913-12-31'))\n",
    "sst_subset5 = sst_anomfull.sel(time=slice('1915-01-01','1918-12-31'))\n",
    "sst_subset6 = sst_anomfull.sel(time=slice('1920-01-01','1921-12-31'))\n",
    "sst_subset7 = sst_anomfull.sel(time=slice('1923-01-01','1927-12-31'))\n",
    "sst_subset8 = sst_anomfull.sel(time=slice('1929-01-01','1931-12-31'))\n",
    "sst_subset9 = sst_anomfull.sel(time=slice('1934-01-01','1939-12-31'))\n",
    "sst_subset10 = sst_anomfull.sel(time=slice('1941-01-01','1948-12-31'))\n",
    "sst_subset11 = sst_anomfull.sel(time=slice('1951-01-01','1955-12-31'))\n",
    "sst_subset12 = sst_anomfull.sel(time=slice('1957-01-01','1958-12-31'))\n",
    "sst_subset13 = sst_anomfull.sel(time=slice('1960-01-01','1962-12-31'))\n",
    "sst_subset13 = sst_anomfull.sel(time=slice('1964-01-01','1965-12-31'))\n",
    "sst_subset14 = sst_anomfull.sel(time=slice('1967-01-01','1971-12-31'))\n",
    "sst_subset15 = sst_anomfull.sel(time=slice('1973-01-01','1976-12-31'))\n",
    "sst_subset16 = sst_anomfull.sel(time=slice('1978-01-01','1979-12-31'))\n",
    "sst_subset17 = sst_anomfull.sel(time=slice('1981-01-01','1982-12-31'))\n",
    "sst_subset18 = sst_anomfull.sel(time=slice('1984-01-01','1991-12-31'))\n",
    "sst_subset19 = sst_anomfull.sel(time=slice('1993-01-01','1998-12-31'))\n",
    "sst_subset20 = sst_anomfull.sel(time=slice('2000-01-01','2002-12-31'))\n",
    "sst_subset21 = sst_anomfull.sel(time=slice('2004-01-01','2006-12-31'))\n",
    "sst_subset22 = sst_anomfull.sel(time=slice('2008-01-01','2010-12-31'))\n",
    "sst_subset23 = sst_anomfull.sel(time=slice('2012-01-01','2015-12-31'))\n",
    "\n",
    "sst_anomtemp = xr.merge([sst_subset1, sst_subset2, sst_subset3, sst_subset4, sst_subset5, \n",
    "                   sst_subset6, sst_subset7, sst_subset8, sst_subset9, sst_subset10, \n",
    "                   sst_subset11, sst_subset12, sst_subset13, sst_subset14, sst_subset15, \n",
    "                   sst_subset16, sst_subset17, sst_subset18, sst_subset19, sst_subset20, \n",
    "                   sst_subset21, sst_subset22, sst_subset23])\n",
    "sst_anom = sst_anomtemp['sst']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"/global/scratch/medhap02/ISMData/prmsl.mon.mean.nc\"\n",
    "slp_dat = xr.open_dataset(dataset_url)\n",
    "slp = slp_dat['prmsl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice SLP data to the same duration as precip and calculate monthly anomalies\n",
    "slp_subset = slp.sel(time=slice('1871-01-01','2015-12-31'))\n",
    "slp_clim = slp_subset.groupby('time.month').mean('time')\n",
    "slp_anomfull = slp_subset.groupby(\"time.month\")-slp_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "slp_subset1 = slp_anomfull.sel(time=slice('1900-01-01','1901-12-31'))\n",
    "slp_subset2 = slp_anomfull.sel(time=slice('1903-01-01','1906-12-31'))\n",
    "slp_subset3 = slp_anomfull.sel(time=slice('1908-01-01','1911-12-31'))\n",
    "slp_subset4 = slp_anomfull.sel(time=slice('1913-01-01','1913-12-31'))\n",
    "slp_subset5 = slp_anomfull.sel(time=slice('1915-01-01','1918-12-31'))\n",
    "slp_subset6 = slp_anomfull.sel(time=slice('1920-01-01','1921-12-31'))\n",
    "slp_subset7 = slp_anomfull.sel(time=slice('1923-01-01','1927-12-31'))\n",
    "slp_subset8 = slp_anomfull.sel(time=slice('1929-01-01','1931-12-31'))\n",
    "slp_subset9 = slp_anomfull.sel(time=slice('1934-01-01','1939-12-31'))\n",
    "slp_subset10 = slp_anomfull.sel(time=slice('1941-01-01','1948-12-31'))\n",
    "slp_subset11 = slp_anomfull.sel(time=slice('1951-01-01','1955-12-31'))\n",
    "slp_subset12 = slp_anomfull.sel(time=slice('1957-01-01','1958-12-31'))\n",
    "slp_subset13 = slp_anomfull.sel(time=slice('1960-01-01','1962-12-31'))\n",
    "slp_subset13 = slp_anomfull.sel(time=slice('1964-01-01','1965-12-31'))\n",
    "slp_subset14 = slp_anomfull.sel(time=slice('1967-01-01','1971-12-31'))\n",
    "slp_subset15 = slp_anomfull.sel(time=slice('1973-01-01','1976-12-31'))\n",
    "slp_subset16 = slp_anomfull.sel(time=slice('1978-01-01','1979-12-31'))\n",
    "slp_subset17 = slp_anomfull.sel(time=slice('1981-01-01','1982-12-31'))\n",
    "slp_subset18 = slp_anomfull.sel(time=slice('1984-01-01','1991-12-31'))\n",
    "slp_subset19 = slp_anomfull.sel(time=slice('1993-01-01','1998-12-31'))\n",
    "slp_subset20 = slp_anomfull.sel(time=slice('2000-01-01','2002-12-31'))\n",
    "slp_subset21 = slp_anomfull.sel(time=slice('2004-01-01','2006-12-31'))\n",
    "slp_subset22 = slp_anomfull.sel(time=slice('2008-01-01','2010-12-31'))\n",
    "slp_subset23 = slp_anomfull.sel(time=slice('2012-01-01','2015-12-31'))\n",
    "\n",
    "slp_anomtemp = xr.merge([slp_subset1, slp_subset2, slp_subset3, slp_subset4, slp_subset5, \n",
    "                   slp_subset6, slp_subset7, slp_subset8, slp_subset9, slp_subset10, \n",
    "                   slp_subset11, slp_subset12, slp_subset13, slp_subset14, slp_subset15, \n",
    "                   slp_subset16, slp_subset17, slp_subset18, slp_subset19, slp_subset20, \n",
    "                   slp_subset21, slp_subset22, slp_subset23])\n",
    "slp_anom = slp_anomtemp['prmsl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"MSE_20thcentury.nc\"\n",
    "mse_dat1 = xr.open_dataset('/global/scratch/medhap02/ISMData/MSE_20thcentury.nc')\n",
    "mse_dat = mse_dat1.rename({'LON':'lon', 'LAT':'lat','TIME':'time'})\n",
    "mse = mse_dat['MSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice MSE data to the same duration as precip and calculate monthly anomalies\n",
    "mse_subset = mse.sel(time=slice('1871-01-30','2017-01-01'))\n",
    "mse_clim = mse_subset.groupby('time.month').mean('time')\n",
    "mse_anomfull = mse_subset.groupby(\"time.month\")-mse_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_subset1 = mse_anomfull.sel(time=slice('1900-01-01','1901-12-31'))\n",
    "mse_subset2 = mse_anomfull.sel(time=slice('1903-01-01','1906-12-31'))\n",
    "mse_subset3 = mse_anomfull.sel(time=slice('1908-01-01','1911-12-31'))\n",
    "mse_subset4 = mse_anomfull.sel(time=slice('1913-01-01','1913-12-31'))\n",
    "mse_subset5 = mse_anomfull.sel(time=slice('1915-01-01','1918-12-31'))\n",
    "mse_subset6 = mse_anomfull.sel(time=slice('1920-01-01','1921-12-31'))\n",
    "mse_subset7 = mse_anomfull.sel(time=slice('1923-01-01','1927-12-31'))\n",
    "mse_subset8 = mse_anomfull.sel(time=slice('1929-01-01','1931-12-31'))\n",
    "mse_subset9 = mse_anomfull.sel(time=slice('1934-01-01','1939-12-31'))\n",
    "mse_subset10 = mse_anomfull.sel(time=slice('1941-01-01','1948-12-31'))\n",
    "mse_subset11 = mse_anomfull.sel(time=slice('1951-01-01','1955-12-31'))\n",
    "mse_subset12 = mse_anomfull.sel(time=slice('1957-01-01','1958-12-31'))\n",
    "mse_subset13 = mse_anomfull.sel(time=slice('1960-01-01','1962-12-31'))\n",
    "mse_subset13 = mse_anomfull.sel(time=slice('1964-01-01','1965-12-31'))\n",
    "mse_subset14 = mse_anomfull.sel(time=slice('1967-01-01','1971-12-31'))\n",
    "mse_subset15 = mse_anomfull.sel(time=slice('1973-01-01','1976-12-31'))\n",
    "mse_subset16 = mse_anomfull.sel(time=slice('1978-01-01','1979-12-31'))\n",
    "mse_subset17 = mse_anomfull.sel(time=slice('1981-01-01','1982-12-31'))\n",
    "mse_subset18 = mse_anomfull.sel(time=slice('1984-01-01','1991-12-31'))\n",
    "mse_subset19 = mse_anomfull.sel(time=slice('1993-01-01','1998-12-31'))\n",
    "mse_subset20 = mse_anomfull.sel(time=slice('2000-01-01','2002-12-31'))\n",
    "mse_subset21 = mse_anomfull.sel(time=slice('2004-01-01','2006-12-31'))\n",
    "mse_subset22 = mse_anomfull.sel(time=slice('2008-01-01','2010-12-31'))\n",
    "mse_subset23 = mse_anomfull.sel(time=slice('2012-01-01','2015-12-31'))\n",
    "\n",
    "mse_anomtemp = xr.merge([mse_subset1, mse_subset2, mse_subset3, mse_subset4, mse_subset5, \n",
    "                   mse_subset6, mse_subset7, mse_subset8, mse_subset9, mse_subset10, \n",
    "                   mse_subset11, mse_subset12, mse_subset13, mse_subset14, mse_subset15, \n",
    "                   mse_subset16, mse_subset17, mse_subset18, mse_subset19, mse_subset20, \n",
    "                   mse_subset21, mse_subset22, mse_subset23])\n",
    "mse_anom = mse_anomtemp['MSE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPT original\n",
    "\n",
    "#DSST1\n",
    "latrange1 = sst_anom.sel(lat = slice(5, -20)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "marchdata1 = sst_anom.sel(lat = slice(5, -20), lon = slice(150, 170), time = (sst_anom['time.month']==3))\n",
    "marchSST1 = marchdata1.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean1 = (marchSST1*weights1).mean({'lon', 'lat'})/weights1.mean() \n",
    "\n",
    "aprildata1 = sst_anom.sel(lat = slice(5, -20), lon = slice(150, 170), time = (sst_anom['time.month']==4))\n",
    "aprilSST1 = aprildata1.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean1 = (aprilSST1*weights1).mean({'lon', 'lat'})/weights1.mean() \n",
    "\n",
    "maydata1 = sst_anom.sel(lat = slice(5, -20), lon = slice(150, 170), time = (sst_anom['time.month']==5))\n",
    "maySST1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = (maySST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "marchmean1.time.data = maymean1.time.data\n",
    "aprilmean1.time.data = maymean1.time.data\n",
    "DSST1 = (maymean1 - marchmean1)\n",
    "\n",
    "#DSST2\n",
    "latrange2 = sst_anom.sel(lat = slice(10, -10)).lat\n",
    "weights2 = np.cos(latrange2*np.pi/180)\n",
    "\n",
    "marchdata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(250, 280), time = (sst_anom['time.month']==3))\n",
    "marchSST2 = marchdata2.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean2 = (marchSST2*weights2).mean({'lon', 'lat'})/weights2.mean()\n",
    "\n",
    "aprildata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(250, 280), time = (sst_anom['time.month']==4))\n",
    "aprilSST2 = aprildata2.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean2 = (aprilSST2*weights2).mean({'lon', 'lat'})/weights2.mean() \n",
    "\n",
    "maydata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(250, 280), time = (sst_anom['time.month']==5))\n",
    "maySST2 = maydata2.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean2 = (maySST2*weights2).mean({'lon', 'lat'})/weights2.mean()\n",
    "\n",
    "marchmean2.time.data = maymean2.time.data\n",
    "aprilmean2.time.data = maymean2.time.data\n",
    "DSST2 = (maymean2 - marchmean2)\n",
    "\n",
    "EPToriginal = DSST1 - DSST2\n",
    "EPTstd = EPToriginal.std()\n",
    "EPTmean = EPToriginal.mean()\n",
    "EPToriginal = (EPToriginal - EPTmean)/EPTstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPT centered on equator\n",
    "#(30n-30s, 155-175e)\n",
    "#(10n-10s, 115-80w)\n",
    "\n",
    "#DSST1\n",
    "latrange1 = sst_anom.sel(lat = slice(30, -30)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "marchdata1 = sst_anom.sel(lat = slice(30, -30), lon = slice(155, 175), time = (sst_anom['time.month']==3))\n",
    "marchSST1 = marchdata1.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean1 = (marchSST1*weights1).mean({'lon', 'lat'})/weights1.mean() \n",
    "\n",
    "aprildata1 = sst_anom.sel(lat = slice(30, -30), lon = slice(155, 175), time = (sst_anom['time.month']==4))\n",
    "aprilSST1 = aprildata1.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean1 = (aprilSST1*weights1).mean({'lon', 'lat'})/weights1.mean() \n",
    "\n",
    "maydata1 = sst_anom.sel(lat = slice(30, -30), lon = slice(155, 175), time = (sst_anom['time.month']==5))\n",
    "maySST1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = (maySST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "marchmean1.time.data = maymean1.time.data\n",
    "aprilmean1.time.data = maymean1.time.data\n",
    "DSST1maymarcentered = maymean1-marchmean1\n",
    "\n",
    "#DSST2\n",
    "latrange2 = sst_anom.sel(lat = slice(10, -10)).lat\n",
    "weights2 = np.cos(latrange2*np.pi/180)\n",
    "\n",
    "marchdata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(245, 280), time = (sst_anom['time.month']==3))\n",
    "marchSST2 = marchdata2.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean2 = (marchSST2*weights2).mean({'lon', 'lat'})/weights2.mean()\n",
    "\n",
    "aprildata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(245, 280), time = (sst_anom['time.month']==4))\n",
    "aprilSST2 = aprildata2.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean2 = (aprilSST2*weights2).mean({'lon', 'lat'})/weights2.mean() \n",
    "\n",
    "maydata2 = sst_anom.sel(lat = slice(10, -10), lon = slice(245, 280), time = (sst_anom['time.month']==5))\n",
    "maySST2 = maydata2.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean2 = (maySST2*weights2).mean({'lon', 'lat'})/weights2.mean()\n",
    "\n",
    "marchmean2.time.data = maymean2.time.data\n",
    "aprilmean2.time.data = maymean2.time.data\n",
    "DSST2maymarcentered = maymean2-marchmean2\n",
    "\n",
    "EPTmaymarcentered = DSST1maymarcentered - DSST2maymarcentered\n",
    "EPTstd = EPTmaymarcentered.std()\n",
    "EPTmean = EPTmaymarcentered.mean()\n",
    "EPTmaymarcentered = (EPTmaymarcentered - EPTmean)/EPTstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPT Original 0.4090730265875154\n",
      "DSST1(australia) 0.12665882952604268\n",
      "DSST2(pacific) -0.4011344140241192\n",
      "\n",
      "EPT May minus March expanded and centered 0.47599220442933515\n",
      "DSST1(australia) may-march centered 0.2736985273531448\n",
      "DSST2(pacific) may-march expanded -0.39627879610891786\n"
     ]
    }
   ],
   "source": [
    "precipa_jjas.time.data = EPToriginal.time.data\n",
    "\n",
    "eptoriginal_subtraction = correlation(EPToriginal, precipa_jjas, dims='time')\n",
    "print(\"EPT Original\", eptoriginal_subtraction.data)\n",
    "ept_australia = correlation(DSST1, precipa_jjas, dims='time')\n",
    "print(\"DSST1(australia)\", ept_australia.data)\n",
    "ept_pacific = correlation(DSST2, precipa_jjas, dims='time')\n",
    "print(\"DSST2(pacific)\", ept_pacific.data)\n",
    "\n",
    "print()\n",
    "eptmaymarcentered_subtraction = correlation(EPTmaymarcentered, precipa_jjas, dims='time')\n",
    "print(\"EPT May minus March expanded and centered\", eptmaymarcentered_subtraction.data)\n",
    "ept_australia = correlation(DSST1maymarcentered, precipa_jjas, dims='time')\n",
    "print(\"DSST1(australia) may-march centered\", ept_australia.data)\n",
    "ept_pacific = correlation(DSST2maymarcentered, precipa_jjas, dims='time')\n",
    "print(\"DSST2(pacific) may-march expanded\", ept_pacific.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CP-ENSOpredictor\n",
    "\n",
    "#DSST1\n",
    "latrange1 = sst_anom.sel(lat = slice(-10, -25)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "aprildata1 = sst_anom.sel(lat = slice(-10, -25), lon = slice(170, 200), time = (sst_anom['time.month']==4))\n",
    "aprilSST1 = aprildata1.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean1 = (aprilSST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "maydata1 = sst_anom.sel(lat = slice(-10, -25), lon = slice(170, 200), time = (sst_anom['time.month']==5))\n",
    "maySST1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = (maySST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "aprilmean1.time.data = maymean1.time.data\n",
    "DSST1 = maymean1 - aprilmean1\n",
    "\n",
    "#DSST2\n",
    "latrange2 = sst_anom.sel(lat = slice(20, 5)).lat\n",
    "weights2 = np.cos(latrange2*np.pi/180)\n",
    "\n",
    "aprildata2 = sst_anom.sel(lat = slice(20, 5), lon = slice(180, 210), time = (sst_anom['time.month']==4))\n",
    "aprilSST2 = aprildata2.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean2 = (aprilSST2*weights2).mean({'lon', 'lat'})/weights2.mean()\n",
    "                          \n",
    "maydata2 = sst_anom.sel(lat = slice(20, 5), lon = slice(180, 210), time = (sst_anom['time.month']==5))\n",
    "maySST2 = maydata2.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean2 = (maySST2*weights2).mean({'lon', 'lat'})/weights2.mean()\n",
    "                          \n",
    "aprilmean2.time.data = maymean2.time.data\n",
    "DSST2 = maymean2 - aprilmean2\n",
    "\n",
    "CPToriginal = DSST1 - DSST2\n",
    "CPTstd = CPToriginal.std()\n",
    "CPTmean = CPToriginal.mean()\n",
    "CPToriginal = (CPToriginal - CPTmean)/CPTstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(55-5s, 175e-155w)\n",
    "latrange1 = sst_anom.sel(lat = slice(-5, -55)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "aprildata1 = sst_anom.sel(lat = slice(-5, -55), lon = slice(175, 205), time = (sst_anom['time.month']==4))\n",
    "aprilSST1 = aprildata1.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean1 = (aprilSST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "maydata1 = sst_anom.sel(lat = slice(-5, -55), lon = slice(175, 205), time = (sst_anom['time.month']==5))\n",
    "maySST1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = (maySST1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "aprilmean1.time.data = maymean1.time.data\n",
    "DSST1new = maymean1 - aprilmean1\n",
    "\n",
    "CPT = DSST1new\n",
    "CPTstd = CPT.std()\n",
    "CPTmean = CPT.mean()\n",
    "CPT = (CPT - CPTmean)/CPTstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPT Original 0.3021634264413822\n",
      "DSST1 0.33710169311785176\n",
      "DSST2 -0.06835847735950427\n",
      "\n",
      "CPT New 0.4316652279987759\n",
      "DSST 0.43166521784841083\n"
     ]
    }
   ],
   "source": [
    "cptoriginal_subtraction = correlation(CPToriginal, precipa_jjas, dims='time')\n",
    "print(\"CPT Original\", cptoriginal_subtraction.data)\n",
    "cpt_southpacific = correlation(DSST1, precipa_jjas, dims='time')\n",
    "print(\"DSST1\", cpt_southpacific.data)\n",
    "cpt_northpacific = correlation(DSST2, precipa_jjas, dims='time')\n",
    "print(\"DSST2\", cpt_northpacific.data)\n",
    "\n",
    "print()\n",
    "cptnew = correlation(CPT, precipa_jjas, dims='time')\n",
    "print(\"CPT New\", cptnew.data)\n",
    "cpt_pacific = correlation(DSST1new, precipa_jjas, dims='time')\n",
    "print(\"DSST\", cpt_pacific.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSH 1 (atlantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mega-ENSOpredictor\n",
    "\n",
    "#NPcalculation\n",
    "latrange1 = slp_anom.sel(lat = slice(-40, -10)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "marchdata1 = slp_anom.sel(lat = slice(-40, -10), lon = slice(200, 270), time = (slp_anom['time.month']==3))\n",
    "marchSLP1 = marchdata1.sel(time=slice('1900-03-01','2015-03-01'))\n",
    "marchmean1 = ((marchSLP1*weights1).mean({'lon', 'lat'})/weights1.mean())\n",
    "\n",
    "aprildata1 = slp_anom.sel(lat = slice(-40, -10), lon = slice(200, 270), time = (slp_anom['time.month']==4))\n",
    "aprilSLP1 = aprildata1.sel(time=slice('1900-04-01','2015-04-01'))\n",
    "aprilmean1 = ((aprilSLP1*weights1).mean({'lon', 'lat'})/weights1.mean())\n",
    "\n",
    "maydata1 = slp_anom.sel(lat = slice(-40, -10), lon = slice(200, 270), time = (slp_anom['time.month']==5))\n",
    "maySLP1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = ((maySLP1*weights1).mean({'lon', 'lat'})/weights1.mean())\n",
    "\n",
    "marchmean1.time.data = maymean1.time.data\n",
    "aprilmean1.time.data = maymean1.time.data\n",
    "NP = ((aprilmean1 + maymean1)/2)\n",
    "\n",
    "#SPcalculation\n",
    "latrange2 = slp_anom.sel(lat = slice(10, 30)).lat\n",
    "weights2 = np.cos(latrange2*np.pi/180)\n",
    "\n",
    "marchdata2 = slp_anom.sel(lat = slice(10, 30), lon = slice(180, 230), time = (slp_anom['time.month']==3))\n",
    "marchSLP2 = marchdata2.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean2 = ((marchSLP2*weights2).mean({'lon', 'lat'})/weights2.mean())\n",
    "\n",
    "aprildata2 = slp_anom.sel(lat = slice(10, 30), lon = slice(180, 230), time = (slp_anom['time.month']==4))\n",
    "aprilSLP2 = aprildata2.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean2 = ((aprilSLP2*weights2).mean({'lon', 'lat'})/weights2.mean())\n",
    "\n",
    "maydata2 = slp_anom.sel(lat = slice(10, 30), lon = slice(180, 230), time = (slp_anom['time.month']==5))\n",
    "maySLP2 = maydata2.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean2 = ((maySLP2*weights2).mean({'lon', 'lat'})/weights2.mean())\n",
    "\n",
    "marchmean2.time.data = maymean2.time.data\n",
    "aprilmean2.time.data = maymean2.time.data\n",
    "SP = ((aprilmean2 + maymean2)/2)\n",
    "\n",
    "NParea = (30*weights1.mean() * 70)\n",
    "SParea = (20*weights2.mean() * 50)\n",
    "PSHoriginal = ((NP * NParea) + (SP * SParea))/(NParea + SParea)\n",
    "PSHstd = PSHoriginal.std()\n",
    "PSHmean = PSHoriginal.mean()\n",
    "PSHoriginal = (PSHoriginal - PSHmean)/PSHstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(20-45s, 145-80w)\n",
    "#(15-35n, 170-125w)\n",
    "\n",
    "#mega-ENSOpredictor\n",
    "# shifted boxes\n",
    "\n",
    "#NPcalculation\n",
    "latrange1 = slp_anom.sel(lat = slice(-45, -20)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "marchdata1 = slp_anom.sel(lat = slice(-45, -20), lon = slice(215, 260), time = (slp_anom['time.month']==3))\n",
    "marchSLP1 = marchdata1.sel(time=slice('1900-03-01','2015-03-01'))\n",
    "marchmean1 = ((marchSLP1*weights1).mean({'lon', 'lat'})/weights1.mean())\n",
    "\n",
    "aprildata1 = slp_anom.sel(lat = slice(-45, -20), lon = slice(215, 260), time = (slp_anom['time.month']==4))\n",
    "aprilSLP1 = aprildata1.sel(time=slice('1900-04-01','2015-04-01'))\n",
    "aprilmean1 = ((aprilSLP1*weights1).mean({'lon', 'lat'})/weights1.mean())\n",
    "\n",
    "maydata1 = slp_anom.sel(lat = slice(-45, -20), lon = slice(215, 260), time = (slp_anom['time.month']==5))\n",
    "maySLP1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = ((maySLP1*weights1).mean({'lon', 'lat'})/weights1.mean())\n",
    "\n",
    "marchmean1.time.data = maymean1.time.data\n",
    "aprilmean1.time.data = maymean1.time.data\n",
    "NPshifted = ((marchmean1 + aprilmean1 + maymean1)/3)\n",
    "\n",
    "#SPcalculation\n",
    "latrange2 = slp_anom.sel(lat = slice(15, 35)).lat\n",
    "weights2 = np.cos(latrange2*np.pi/180)\n",
    "\n",
    "marchdata2 = slp_anom.sel(lat = slice(15, 35), lon = slice(190, 235), time = (slp_anom['time.month']==3))\n",
    "marchSLP2 = marchdata2.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean2 = ((marchSLP2*weights2).mean({'lon', 'lat'})/weights2.mean())\n",
    "\n",
    "aprildata2 = slp_anom.sel(lat = slice(15, 35), lon = slice(190, 235), time = (slp_anom['time.month']==4))\n",
    "aprilSLP2 = aprildata2.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean2 = ((aprilSLP2*weights2).mean({'lon', 'lat'})/weights2.mean())\n",
    "\n",
    "maydata2 = slp_anom.sel(lat = slice(15, 35), lon = slice(190, 235), time = (slp_anom['time.month']==5))\n",
    "maySLP2 = maydata2.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean2 = ((maySLP2*weights2).mean({'lon', 'lat'})/weights2.mean())\n",
    "\n",
    "marchmean2.time.data = maymean2.time.data\n",
    "aprilmean2.time.data = maymean2.time.data\n",
    "SPshifted = ((marchmean2 + aprilmean2 + maymean2)/3)\n",
    "\n",
    "NPareashifted = (25*weights1.mean() * 45)\n",
    "SPareashifted = (20*weights2.mean() * 45)\n",
    "PSHshiftedmam = ((NPshifted * NParea) + (SPshifted * SParea))/(NParea + SParea)\n",
    "PSHstd = PSHshiftedmam.std()\n",
    "PSHmean = PSHshiftedmam.mean()\n",
    "PSHshiftedmam = (PSHshiftedmam - PSHmean)/PSHstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSH MAM 0.24828237180324592\n",
      "NP MAM 0.21280531760667154\n",
      "SP MAM 0.21882285167304077\n",
      "\n",
      "PSH Shifted MAM 0.33212898497528126\n",
      "NP Shifted MAM 0.2914889197868212\n",
      "SP ShiftedMAM 0.27130302504067877\n"
     ]
    }
   ],
   "source": [
    "pshmam_subtraction = correlation(PSHoriginal, precipa_jjas, dims='time')\n",
    "print(\"PSH MAM\", pshmam_subtraction.data)\n",
    "pshmam_northpacific = correlation(NP, precipa_jjas, dims='time')\n",
    "print(\"NP MAM\", pshmam_northpacific.data)\n",
    "pshmam_southpacific = correlation(SP, precipa_jjas, dims='time')\n",
    "print(\"SP MAM\", pshmam_southpacific.data)\n",
    "\n",
    "print()\n",
    "pshshiftedmam_subtraction = correlation(PSHshiftedmam, precipa_jjas, dims='time')\n",
    "print(\"PSH Shifted MAM\", pshshiftedmam_subtraction.data)\n",
    "pshshiftedmam_northpacific = correlation(NPshifted, precipa_jjas, dims='time')\n",
    "print(\"NP Shifted MAM\", pshshiftedmam_northpacific.data)\n",
    "pshshiftedmam_southpacific = correlation(SPshifted, precipa_jjas, dims='time')\n",
    "print(\"SP ShiftedMAM\", pshshiftedmam_southpacific.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSH 2 (indian ocean) - new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(0-20n, 40-120e)\n",
    "\n",
    "latrange1 = slp_anom.sel(lat = slice(0, 20)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "marchdata1 = slp_anom.sel(lat = slice(0, 20), lon = slice(40, 120), time = (slp_anom['time.month']==3))\n",
    "marchSLP1 = marchdata1.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean1 = (marchSLP1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "aprildata1 = slp_anom.sel(lat = slice(0, 20), lon = slice(40, 120), time = (slp_anom['time.month']==4))\n",
    "aprilSLP1 = aprildata1.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean1 = (aprilSLP1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "maydata1 = slp_anom.sel(lat = slice(0, 20), lon = slice(40, 120), time = (slp_anom['time.month']==5))\n",
    "maySLP1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = (maySLP1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "marchmean1.time.data = maymean1.time.data\n",
    "aprilmean1.time.data = maymean1.time.data\n",
    "\n",
    "EQindia = (marchmean1 + aprilmean1 + maymean1)/3\n",
    "\n",
    "PSHindia = EQindia\n",
    "PSHstd = PSHindia.std()\n",
    "PSHmean = PSHindia.mean()\n",
    "\n",
    "PSHindia = (PSHindia - PSHmean)/PSHstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSH Equatorial Indian Ocean -0.3177957291633576\n"
     ]
    }
   ],
   "source": [
    "pshnew_india = correlation(PSHindia, precipa_jjas, dims='time')\n",
    "print(\"PSH Equatorial Indian Ocean\", pshnew_india.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSH New \n",
    "(original boxes minus equitorial indian ocean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSHtemp = ((NP * NParea) + (SP * SParea))/(NParea + SParea)\n",
    "PSHnew = PSHtemp - EQindia\n",
    "\n",
    "PSHnewstd = PSHnew.std()\n",
    "PSHnewmean = PSHnew.mean()\n",
    "PSHnew = (PSHnew - PSHnewmean)/PSHnewstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSHtempshifted = ((NPshifted * NPareashifted) + (SPshifted * SPareashifted))/(NPareashifted + SPareashifted)\n",
    "PSHnewshifted = PSHtempshifted - EQindia\n",
    "\n",
    "PSHnewstd = PSHnewshifted.std()\n",
    "PSHnewmean = PSHnewshifted.mean()\n",
    "PSHnewshifted = (PSHnewshifted - PSHnewmean)/PSHnewstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSH Original Boxes minues Equitorial Indian Ocean 0.3525487910815343\n",
      "PSH Original Boxes 0.24828237180324583\n",
      "EQ india -0.31779573783300546\n",
      "\n",
      "PSH Shifted Boxes MAM minues Equitorial Indian Ocean 0.3855575689799471\n",
      "PSH Shifted Boxes MAM 0.34284635449145295\n",
      "EQ india -0.31779573783300546\n"
     ]
    }
   ],
   "source": [
    "pshnew = correlation(PSHnew, precipa_jjas, dims='time')\n",
    "print(\"PSH Original Boxes minues Equitorial Indian Ocean\", pshnew.data)\n",
    "psh_original = correlation(PSHtemp, precipa_jjas, dims='time')\n",
    "print(\"PSH Original Boxes\", psh_original.data)\n",
    "psh_eqindia = correlation(EQindia, precipa_jjas, dims='time')\n",
    "print(\"EQ india\", psh_eqindia.data)\n",
    "\n",
    "print()\n",
    "pshnewshifted = correlation(PSHnewshifted, precipa_jjas, dims='time')\n",
    "print(\"PSH Shifted Boxes MAM minues Equitorial Indian Ocean\", pshnewshifted.data)\n",
    "psh_shiftedMAM = correlation(PSHtempshifted, precipa_jjas, dims='time')\n",
    "print(\"PSH Shifted Boxes MAM\", psh_shiftedMAM.data)\n",
    "psh_eqindia = correlation(EQindia, precipa_jjas, dims='time')\n",
    "print(\"EQ india\", psh_eqindia.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAT (removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAT -0.1763771450127206\n"
     ]
    }
   ],
   "source": [
    "#AnomalousAsianLowpredictor\n",
    "\n",
    "latrange = slp_anom.sel(lat = slice(40, 60)).lat\n",
    "weights = np.cos(latrange*np.pi/180)\n",
    "\n",
    "marchdata = slp_anom.sel(lat = slice(40, 60), lon = slice(95, 125), time = (slp_anom['time.month']==3))\n",
    "marchSLP = marchdata.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean = ((marchSLP*weights).mean({'lon', 'lat'})/weights.mean())\n",
    "\n",
    "maydata = slp_anom.sel(lat = slice(40, 60), lon = slice(95, 125), time = (slp_anom['time.month']==5))\n",
    "maySLP = maydata.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean = ((maySLP*weights).mean({'lon', 'lat'})/weights.mean())\n",
    "\n",
    "marchmean.time.data = maymean.time.data\n",
    "\n",
    "NATprimary = maymean - marchmean\n",
    "NAT = maymean - marchmean\n",
    "#print(NAT)\n",
    "NATstd = NAT.std()\n",
    "NATmean = NAT.mean()\n",
    "NAT = (NAT - NATmean)/NATstd\n",
    "\n",
    "nat = correlation(NAT, precipa_jjas, dims='time')\n",
    "print(\"NAT\", nat.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(0-25n, 45-70e)\n",
    "#(20-40n, 70-90e)\n",
    "\n",
    "latrange1 = mse_anom.sel(lat = slice(0, 25)).lat\n",
    "weights1 = np.cos(latrange1*np.pi/180)\n",
    "\n",
    "marchdata1 = mse_anom.sel(lat = slice(0, 25), lon = slice(45, 70), time = (mse_anom['time.month']==3))\n",
    "marchMSE1 = marchdata1.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean1 = (marchMSE1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "aprildata1 = mse_anom.sel(lat = slice(0, 25), lon = slice(45, 70), time = (mse_anom['time.month']==4))\n",
    "aprilMSE1 = aprildata1.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean1 = (aprilMSE1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "maydata1 = mse_anom.sel(lat = slice(0, 25), lon = slice(45, 70), time = (mse_anom['time.month']==5))\n",
    "mayMSE1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = (mayMSE1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "marchmean1.time.data = maymean1.time.data\n",
    "aprilmean1.time.data = maymean1.time.data\n",
    "\n",
    "MSEleft = maymean1 - marchmean1\n",
    "\n",
    "latrange2 = mse_anom.sel(lat = slice(20, 40)).lat\n",
    "weights2 = np.cos(latrange2*np.pi/180)\n",
    "\n",
    "marchdata2 = mse_anom.sel(lat = slice(20, 40), lon = slice(70, 90), time = (mse_anom['time.month']==3))\n",
    "marchMSE2 = marchdata2.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean2 = ((marchMSE2*weights2).mean({'lon', 'lat'})/weights2.mean())\n",
    "\n",
    "aprildata2 = mse_anom.sel(lat = slice(20, 40), lon = slice(70, 90), time = (mse_anom['time.month']==4))\n",
    "aprilMSE2 = aprildata2.sel(time = slice('1900-04-01', '2015-04-01'))\n",
    "aprilmean2 = ((aprilMSE2*weights2).mean({'lon', 'lat'})/weights2.mean())\n",
    "\n",
    "maydata2 = mse_anom.sel(lat = slice(20, 40), lon = slice(70, 90), time = (mse_anom['time.month']==5))\n",
    "mayMSE2 = maydata2.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean2 = ((mayMSE2*weights2).mean({'lon', 'lat'})/weights2.mean())\n",
    "\n",
    "marchmean2.time.data = maymean2.time.data\n",
    "aprilmean2.time.data = maymean2.time.data\n",
    "\n",
    "MSEright = maymean2 - marchmean2\n",
    "\n",
    "MSEmay_mar = (MSEright + MSEleft)/2\n",
    "MSEstd = MSEmay_mar.std()\n",
    "MSEmean = MSEmay_mar.mean()\n",
    "MSEmay_mar = (MSEmay_mar - MSEmean)/MSEstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (time: 88)>\n",
      "array([ 0.703373, -0.420024, -0.735947, -0.128984,  0.070085, -0.557442,\n",
      "        1.453159,  1.853357,  0.762672, -1.040786, -1.595467,  0.254367,\n",
      "       -0.080102,  0.322635, -0.798798,  0.156482, -0.555605, -1.770474,\n",
      "        0.466213,  0.484568, -0.360855,  1.193541,  0.649579, -1.334648,\n",
      "       -2.218624,  0.348202, -0.561232,  0.678378,  0.992252, -0.525963,\n",
      "       -0.981872,  0.68941 , -0.255552, -0.942193, -0.521181,  1.832442,\n",
      "        0.982721,  0.628098, -1.017553,  0.41852 , -0.521885, -0.210203,\n",
      "       -0.885643,  0.988456,  1.393629, -0.243851,  0.252325, -1.782069,\n",
      "        0.671555, -1.918719,  0.53454 ,  1.117873,  0.796476,  0.325502,\n",
      "        0.145092, -0.622136,  0.608512, -0.988359,  0.456163,  0.555907,\n",
      "       -0.074356,  1.502024,  0.995766, -0.017734, -0.579755,  0.883712,\n",
      "       -1.977925, -1.521291,  0.927713, -1.087153,  0.939036, -0.160292,\n",
      "       -0.10923 , -0.21564 , -1.361189,  0.09094 ,  0.424206, -1.227248,\n",
      "       -0.059124, -0.422256, -0.494859, -1.350032,  0.52287 ,  2.889323,\n",
      "        2.528131,  1.024078, -0.284822, -0.994814])\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1900-05-01 1901-05-01 ... 2015-05-01\n"
     ]
    }
   ],
   "source": [
    "#(45-70n, 95e-150w)\n",
    "\n",
    "latrange = mse_anom.sel(lat = slice(45, 70)).lat\n",
    "weights1 = np.cos(latrange*np.pi/180)\n",
    "\n",
    "marchdata1 = mse_anom.sel(lat = slice(45, 70), lon = slice(95, 210), time = (mse_anom['time.month']==3))\n",
    "marchMSE1 = marchdata1.sel(time = slice('1900-03-01', '2015-03-01'))\n",
    "marchmean1 = (marchMSE1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "maydata1 = mse_anom.sel(lat = slice(45, 70), lon = slice(95, 210), time = (mse_anom['time.month']==5))\n",
    "mayMSE1 = maydata1.sel(time = slice('1900-05-01', '2015-05-01'))\n",
    "maymean1 = (mayMSE1*weights1).mean({'lon', 'lat'})/weights1.mean()\n",
    "\n",
    "marchmean1.time.data = maymean1.time.data\n",
    "\n",
    "MSErussiainitial = maymean1 - marchmean1\n",
    "\n",
    "MSErussia = MSErussiainitial\n",
    "MSEstd = MSErussia.std()\n",
    "MSEmean = MSErussia.mean()\n",
    "MSErussia = (MSErussia - MSEmean)/MSEstd\n",
    "print(MSErussia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE May - March 2 boxes 0.2542827284894997\n",
      "MSE Right 0.22666060063016982\n",
      "MSE Left 0.2565303134495685\n",
      "\n",
      "MSE may - march Russia 0.21993838702674287\n",
      "Correlation between MSE May-March 2 boxes and Russia 0.11566555826864745\n"
     ]
    }
   ],
   "source": [
    "msemay_mar = correlation(MSEmay_mar, precipa_jjas, dims='time')\n",
    "print(\"MSE May - March 2 boxes\", msemay_mar.data)\n",
    "mseeast = correlation(MSEright, precipa_jjas, dims='time')\n",
    "print(\"MSE Right\", mseeast.data)\n",
    "msewest = correlation(MSEleft, precipa_jjas, dims='time')\n",
    "print(\"MSE Left\", msewest.data)\n",
    "print()\n",
    "mserussia = correlation(MSErussia, precipa_jjas, dims='time')\n",
    "print(\"MSE may - march Russia\", mserussia.data)\n",
    "\n",
    "msecorrmay_mar2boxesrussia = correlation(MSEmay_mar, MSErussia, dims='time')\n",
    "print(\"Correlation between MSE May-March 2 boxes and Russia\", msecorrmay_mar2boxesrussia.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3 boxes in May-March mean 0.30656883629138765\n"
     ]
    }
   ],
   "source": [
    "MSEmay_marmean = (MSEright + MSEleft + MSErussiainitial)/3\n",
    "MSEstd = MSEmay_marmean.std()\n",
    "MSEmean = MSEmay_marmean.mean()\n",
    "MSEmay_marmean = (MSEmay_marmean - MSEmean)/MSEstd\n",
    "\n",
    "msemay_mar3boxes = correlation(MSEmay_marmean, precipa_jjas, dims='time')\n",
    "print(\"All 3 boxes in May-March mean\", msemay_mar3boxes.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020 Medha Palavalli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xarrayenv2",
   "language": "python",
   "name": "xarrayenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
